{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Importing Necessary Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "XIL5OCqJ7bh8"
      },
      "outputs": [],
      "source": [
        "# from langchain.chat_models import ChatOpenAI\n",
        "from langchain_openai import ChatOpenAI \n",
        "\n",
        "from langchain.document_loaders import  PyPDFLoader\n",
        "from langchain.vectorstores import  FAISS\n",
        "from langchain.text_splitter import  RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings \n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from time import monotonic\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from dotenv import load_dotenv\n",
        "from langchain.agents import initialize_agent, Tool\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from pprint import pprint\n",
        "import textwrap\n",
        "import os\n",
        "from datasets import Dataset\n",
        "from ragas import evaluate\n",
        "from ragas.metrics import (\n",
        "    answer_correctness,\n",
        "    faithfulness,\n",
        "    answer_relevancy,\n",
        "    context_recall,\n",
        "    answer_similarity\n",
        ")\n",
        "\n",
        "from langgraph.graph import END, StateGraph\n",
        "from typing_extensions import TypedDict\n",
        "from langchain_core.runnables.graph import MermaidDrawMethod\n",
        "from IPython.display import display, Image\n",
        "from langchain.schema import AIMessage\n",
        "from langchain import hub\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from typing import List, Tuple, Annotated, TypedDict\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "\n",
        "import operator\n",
        "import langgraph\n",
        "\n",
        "### Helper functions for the notebook\n",
        "from helper_functions import num_tokens_from_string, replace_t_with_space, replace_double_lines_with_one_line, split_into_chapters,\\\n",
        "analyse_metric_results, escape_quotes, format_state_past_steps, clean_empty_fields_dictionary, process_replanner_output\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "os.environ[\"PYDEVD_WARN_EVALUATION_TIMEOUT\"] = \"100000\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setting Preferred Encoding for PyPDF on Google Colab\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "c6QeKRm37HwC"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding # For using PyPDF on google colab "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setting OPENAI and GROQ API keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')\n",
        "groq_api_key = os.getenv('GROQ_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Defining Path to Harry Potter PDF\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8mUYHG_S6y22"
      },
      "outputs": [],
      "source": [
        "hp_pdf_path =\"Harry_Potter_Book_1_The_Sorcerers_Stone.pdf\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Splitting the PDF into Chapters and Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cDHfDODdTIBY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "17\n"
          ]
        }
      ],
      "source": [
        "chapters = split_into_chapters(hp_pdf_path) \n",
        "chapters = replace_t_with_space(chapters)\n",
        "print(len(chapters))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Defining Prompt Template for Summarization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "49RqsAhDxjFg"
      },
      "outputs": [],
      "source": [
        "summarization_prompt_template = \"\"\"Write an extensive summary of about of the following:\n",
        "\n",
        "{text}\n",
        "\n",
        "SUMMARY:\"\"\"\n",
        "\n",
        "summarization_prompt = PromptTemplate(template=summarization_prompt_template, input_variables=[\"text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Defining Function to Create Chapter Summaries using LLMs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ehe6iObnx4l9"
      },
      "outputs": [],
      "source": [
        "def create_chapter_summary(chapter):\n",
        "    \"\"\"\n",
        "    Creates a summary of a chapter using a large language model (LLM).\n",
        "\n",
        "    Args:\n",
        "        chapter: A Document object representing the chapter to summarize.\n",
        "\n",
        "    Returns:\n",
        "        A Document object containing the summary of the chapter.\n",
        "    \"\"\"\n",
        "\n",
        "    chapter_txt = chapter.page_content  # Extract chapter text\n",
        "    model_name = \"gpt-3.5-turbo-0125\"  # Specify LLM model\n",
        "    llm = ChatOpenAI(temperature=0, model_name=model_name)  # Create LLM instance\n",
        "    gpt_35_turbo_max_tokens = 16000  # Maximum token limit for the LLM\n",
        "    verbose = False  # Set to True for more detailed output\n",
        "\n",
        "    # Calculate number of tokens in the chapter text\n",
        "    num_tokens = num_tokens_from_string(chapter_txt, model_name)\n",
        "\n",
        "    # Choose appropriate chain type based on token count\n",
        "    if num_tokens < gpt_35_turbo_max_tokens:\n",
        "        chain = load_summarize_chain(llm, chain_type=\"stuff\", prompt=summarization_prompt, verbose=verbose)\n",
        "    else:\n",
        "        chain = load_summarize_chain(llm, chain_type=\"map_reduce\", map_prompt=summarization_prompt, combine_prompt=summarization_prompt, verbose=verbose)\n",
        "\n",
        "    start_time = monotonic()  # Start timer\n",
        "    doc_chapter = Document(page_content=chapter_txt)  # Create Document object for chapter\n",
        "    summary = chain.invoke([doc_chapter])  # Generate summary using the chain\n",
        "    print(f\"Chain type: {chain.__class__.__name__}\")  # Print chain type\n",
        "    print(f\"Run time: {monotonic() - start_time}\")  # Print execution time\n",
        "\n",
        "    # Clean up summary text\n",
        "    summary = replace_double_lines_with_one_line(summary[\"output_text\"])\n",
        "\n",
        "    # Create Document object for summary\n",
        "    doc_summary = Document(page_content=summary, metadata=chapter.metadata)\n",
        "\n",
        "    return doc_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generating Summaries for Each Chapter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4UBurLsMCHj",
        "outputId": "668932cf-02d8-446d-e0ed-3f85b30d3bba"
      },
      "outputs": [],
      "source": [
        "chapter_summaries = []\n",
        "for chapter in chapters:\n",
        "    chapter_summaries.append(create_chapter_summary(chapter))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Function to Encode a Book into a Vector Store using OpenAI Embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9t1Kq6fGS0EA"
      },
      "outputs": [],
      "source": [
        "def encode_book(path, chunk_size=1000, chunk_overlap=200):\n",
        "    \"\"\"\n",
        "    Encodes a PDF book into a vector store using OpenAI embeddings.\n",
        "\n",
        "    Args:\n",
        "        path: The path to the PDF file.\n",
        "        chunk_size: The desired size of each text chunk.\n",
        "        chunk_overlap: The amount of overlap between consecutive chunks.\n",
        "\n",
        "    Returns:\n",
        "        A FAISS vector store containing the encoded book content.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load PDF documents\n",
        "    loader = PyPDFLoader(path)\n",
        "    documents = loader.load()\n",
        "\n",
        "    # Split documents into chunks\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=chunk_size, chunk_overlap=chunk_overlap, length_function=len\n",
        "    )\n",
        "    texts = text_splitter.split_documents(documents)\n",
        "    cleaned_texts = replace_t_with_space(texts)\n",
        "\n",
        "    # Create embeddings and vector store\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "    vectorstore = FAISS.from_documents(cleaned_texts, embeddings)\n",
        "\n",
        "    return vectorstore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Encoding Chapter Summaries into Vector Store\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "FHt9Y12gMp2z"
      },
      "outputs": [],
      "source": [
        "def encode_chapter_summaries(chapter_summaries):\n",
        "    \"\"\"\n",
        "    Encodes a list of chapter summaries into a vector store using OpenAI embeddings.\n",
        "\n",
        "    Args:\n",
        "        chapter_summaries: A list of Document objects representing the chapter summaries.\n",
        "\n",
        "    Returns:\n",
        "        A FAISS vector store containing the encoded chapter summaries.\n",
        "    \"\"\"\n",
        "\n",
        "    embeddings = OpenAIEmbeddings()  # Create OpenAI embeddings\n",
        "    chapter_summaries_vectorstore = FAISS.from_documents(chapter_summaries, embeddings)  # Create vector store\n",
        "    return chapter_summaries_vectorstore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating Vector Stores and Retrievers for Book and Chapter Summaries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\N7\\PycharmProjects\\llm_tasks\\RAG-Harry-Potter\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "# ### IF VECTOR STORES ALREADY EXIST, LOAD THEM\n",
        "if os.path.exists(\"chunks_vector_store\") and os.path.exists(\"chapter_summaries_vector_store\"):\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "    chunks_vector_store =  FAISS.load_local(\"chunks_vector_store\", embeddings, allow_dangerous_deserialization=True)\n",
        "    chapter_summaries_vector_store =  FAISS.load_local(\"chapter_summaries_vector_store\", embeddings, allow_dangerous_deserialization=True)\n",
        "\n",
        "else:\n",
        "    chunks_vector_store = encode_book(hp_pdf_path, chunk_size=1000, chunk_overlap=200)\n",
        "    chapter_summaries_vector_store = encode_chapter_summaries(chapter_summaries)\n",
        "\n",
        "    chunks_vector_store.save_local(\"chunks_vector_store\") # save the chunks_vector_store\n",
        "    chapter_summaries_vector_store.save_local(\"chapter_summaries_vector_store\") # save the chapter_summaries_vector_store\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create retrievers from the vector stores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "chunks_query_retriever = chunks_vector_store.as_retriever(search_kwargs={\"k\": 1})     \n",
        "chapter_summaries_query_retriever = chapter_summaries_vector_store.as_retriever(search_kwargs={\"k\": 1})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create graph nodes and LLM function for the nodes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Agrregate retrieved content as string context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def retrieve_context_per_question(state):\n",
        " \n",
        "    # Retrieve relevant documents\n",
        "    print(\"Retrieving relevant chunks...\")\n",
        "    question = state[\"question\"]\n",
        "    docs = chunks_query_retriever.get_relevant_documents(question)\n",
        "\n",
        "    # Concatenate document content\n",
        "    context = \" \".join(doc.page_content for doc in docs)\n",
        "\n",
        "\n",
        "    print(\"Retrieving relevant chapter summaries...\")\n",
        "    question = state[\"question\"]\n",
        "\n",
        "    docs_summaries = chapter_summaries_query_retriever.get_relevant_documents(state[\"question\"])\n",
        "\n",
        "\n",
        "    # Concatenate chapter summaries with citation information\n",
        "    context_summaries = \"\".join(\n",
        "        f\"{doc.page_content} (Chapter {doc.metadata['chapter']})\" for doc in docs_summaries\n",
        "    )\n",
        "\n",
        "    all_contexts = context + context_summaries\n",
        "    all_contexts = escape_quotes(all_contexts)\n",
        "\n",
        "    return {\"context\": all_contexts, \"question\": question}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LLM based function to distill only relevant retrieved content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "keep_only_relevant_content_prompt_template = \"\"\"you receive a query: {query} and retrieved docuemnts: {retrieved_documents} from a vector store.\n",
        " You need to filter the retrieved data and keep only the sentences that are relevant, but all of them.\n",
        " you should output the distilled content in a json format. \n",
        " REMEMBER: the output has to be a json containing ALL the relevant sentences, and not the answer to the query. {format_instructions}\"\"\"\n",
        "\n",
        "class QuestionAnswer(BaseModel):\n",
        "    relevant_content: str = Field(description=\"The relevant content from the retrieved documents that is relevant to the query.\")\n",
        "\n",
        "\n",
        "json_parser = JsonOutputParser(pydantic_object=QuestionAnswer)\n",
        "\n",
        "keep_only_relevant_content_prompt = PromptTemplate(\n",
        "    template=keep_only_relevant_content_prompt_template,\n",
        "    input_variables=[\"query\", \"retrieved_documents\"],\n",
        "    partial_variables={\"format_instructions\": json_parser.get_format_instructions()}, \n",
        ")\n",
        "\n",
        "keep_only_relevant_content_llm = ChatGroq(temperature=0, model_name=\"llama3-70b-8192\", groq_api_key=groq_api_key, max_tokens=4000)\n",
        "keep_only_relevant_content_chain = keep_only_relevant_content_prompt | keep_only_relevant_content_llm | json_parser\n",
        "\n",
        "def keep_only_relevant_content(state):\n",
        "    \"\"\"\n",
        "    Keeps only the relevant content from the retrieved documents that is relevant to the query.\n",
        "\n",
        "    Args:\n",
        "        question: The query question.\n",
        "        context: The retrieved documents.\n",
        "        chain: The LLMChain instance.\n",
        "\n",
        "    Returns:\n",
        "        The relevant content from the retrieved documents that is relevant to the query.\n",
        "    \"\"\"\n",
        "    question = state[\"question\"]\n",
        "    context = state[\"context\"]\n",
        "\n",
        "    input_data = {\n",
        "    \"query\": question,\n",
        "    \"retrieved_documents\": context\n",
        "}\n",
        "    print(\"keeping only the relevant content...\")\n",
        "    # Invoke the chain to keep only the relevant content\n",
        "    output = keep_only_relevant_content_chain.invoke(input_data)\n",
        "    relevant_content = output[\"relevant_content\"]\n",
        "    relevant_content = \". \".join(relevant_content)\n",
        "    relevant_content = escape_quotes(relevant_content)\n",
        "\n",
        "    return {\"context\": relevant_content, \"question\": question}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LLM based function to re-write a question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Question Re-writer\n",
        "\n",
        "class RewriteQuestion(BaseModel):\n",
        "    \"\"\"\n",
        "    Output schema for the rewritten question.\n",
        "    \"\"\"\n",
        "    rewritten_question: str = Field(description=\"The improved question optimized for vectorstore retrieval.\")\n",
        "\n",
        "rewrite_question_string_parser = JsonOutputParser(pydantic_object=RewriteQuestion)\n",
        "\n",
        "\n",
        "rewrite_llm = ChatGroq(temperature=0, model_name=\"llama3-70b-8192\", groq_api_key=groq_api_key, max_tokens=4000)\n",
        "rewrite_prompt_template = \"\"\"You are a question re-writer that converts an input question to a better version optimized for vectorstore retrieval.\n",
        " Analyze the input question {question} and try to reason about the underlying semantic intent / meaning.\n",
        " {format_instructions}\n",
        " \"\"\"\n",
        "\n",
        "rewrite_prompt = PromptTemplate(\n",
        "    template=rewrite_prompt_template,\n",
        "    input_variables=[\"question\"],\n",
        "    partial_variables={\"format_instructions\": rewrite_question_string_parser.get_format_instructions()},\n",
        ")\n",
        "\n",
        "question_rewriter = rewrite_prompt | rewrite_llm | rewrite_question_string_parser  # Combine prompt, LLM, and parser\n",
        "\n",
        "def rewrite_question(state):\n",
        "    \"\"\"Rewrites the given question using the LLM.\"\"\"\n",
        "    question = state[\"question\"]\n",
        "    print(\"Rewriting the question...\")\n",
        "    result = question_rewriter.invoke({\"question\": question})\n",
        "    new_question = result[\"rewritten_question\"]\n",
        "    return {\"question\": new_question}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LLM based function to answer a question given context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "class QuestionAnswerFromContext(BaseModel):\n",
        "    answer_based_on_content: str = Field(description=\"generates an answer to a query based on a given context.\")\n",
        "\n",
        "question_answer_from_context_json_parser = JsonOutputParser(pydantic_object=QuestionAnswerFromContext)\n",
        "question_answer_from_context_llm = ChatGroq(temperature=0, model_name=\"llama3-70b-8192\", groq_api_key=groq_api_key, max_tokens=4000)\n",
        "\n",
        "question_answer_from_context_prompt_template = \"\"\"you receive a query: {query} and a context: {context}. \n",
        "You need to answer the query from the context. the output has to be a json containing the answer to the query.\n",
        " {format_instructions}\"\"\"\n",
        "\n",
        "question_answer_from_context_prompt = PromptTemplate(\n",
        "    template=question_answer_from_context_prompt_template,\n",
        "    input_variables=[\"query\", \"context\"],\n",
        "    partial_variables={\"format_instructions\": question_answer_from_context_json_parser.get_format_instructions()},\n",
        ")\n",
        "question_answer_from_context_chain = question_answer_from_context_prompt | question_answer_from_context_llm | question_answer_from_context_json_parser\n",
        "\n",
        "def answer_question_from_context(state):\n",
        "    \"\"\"\n",
        "    Answers a question from a given context.\n",
        "\n",
        "    Args:\n",
        "        question: The query question.\n",
        "        context: The context to answer the question from.\n",
        "        chain: The LLMChain instance.\n",
        "\n",
        "    Returns:\n",
        "        The answer to the question from the context.\n",
        "    \"\"\"\n",
        "    question = state[\"question\"]\n",
        "    context = state[\"context\"]\n",
        "\n",
        "    input_data = {\n",
        "    \"query\": question,\n",
        "    \"context\": context\n",
        "}\n",
        "    print(\"Answering the question from the retrieved context...\")\n",
        "\n",
        "    # Invoke the chain to answer the question from the context\n",
        "    output = question_answer_from_context_chain.invoke(input_data)\n",
        "    answer = output[\"answer_based_on_content\"]\n",
        "    return {\"answer\": answer, \"context\": context, \"question\": question}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create graph edges"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LLM based function to determine if retrieved content is relevant to question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "is_relevant_content_prompt_template = \"\"\"you receive a query: {query} and a context: {context} retrieved from a vector store. \n",
        "You need to determine if the document is relevant to the query. \n",
        "\n",
        "{format_instructions}\"\"\"\n",
        "\n",
        "class Relevance(BaseModel):\n",
        "    is_relevant: bool = Field(description=\"Whether the document is relevant to the query.\")\n",
        "    explanation: str = Field(description=\"An explanation of why the document is relevant or not.\")\n",
        "\n",
        "is_relevant_json_parser = JsonOutputParser(pydantic_object=Relevance)\n",
        "is_relevant_llm = ChatGroq(temperature=0, model_name=\"llama3-70b-8192\", groq_api_key=groq_api_key, max_tokens=4000)\n",
        "\n",
        "is_relevant_content_prompt = PromptTemplate(\n",
        "    template=is_relevant_content_prompt_template,\n",
        "    input_variables=[\"query\", \"context\"],\n",
        "    partial_variables={\"format_instructions\": is_relevant_json_parser.get_format_instructions()},\n",
        ")\n",
        "is_relevant_content_chain = is_relevant_content_prompt | is_relevant_llm | is_relevant_json_parser\n",
        "\n",
        "def is_relevant_content(state):\n",
        "    \"\"\"\n",
        "    Determines if the document is relevant to the query.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    question = state[\"question\"]\n",
        "    context = state[\"context\"]\n",
        "\n",
        "    input_data = {\n",
        "    \"query\": question,\n",
        "    \"context\": context\n",
        "}\n",
        "\n",
        "    # Invoke the chain to determine if the document is relevant\n",
        "    output = is_relevant_content_chain.invoke(input_data)\n",
        "    print(\"Determining if the document is relevant...\")\n",
        "    if output[\"is_relevant\"] == True:\n",
        "        print(\"The document is relevant.\")\n",
        "        return \"relevant\"\n",
        "    else:\n",
        "        print(\"The document is not relevant.\")\n",
        "        return \"not relevant\"\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LLM chain to check if an answer is hallucination"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "class is_grounded_on_facts(BaseModel):\n",
        "    \"\"\"\n",
        "    Output schema for the rewritten question.\n",
        "    \"\"\"\n",
        "    grounded_on_facts: bool = Field(description=\"Answer is grounded in the facts, 'yes' or 'no'\")\n",
        "    explanation: str = Field(description=\"An explanation of why the answer is grounded in the facts or not.\")\n",
        "\n",
        "grounded_on_facts_parser = JsonOutputParser(pydantic_object=is_grounded_on_facts)\n",
        "is_grounded_on_facts_llm = ChatGroq(temperature=0, model_name=\"llama3-70b-8192\", groq_api_key=groq_api_key, max_tokens=4000)\n",
        "is_grounded_on_facts_prompt_template = \"\"\"You are a fact-checker that determines if the answer to the question is grounded in the facts.\n",
        " Analyze the input context {context} and the answer {answer} and determine if the answer is grounded in the facts.\n",
        " {format_instructions}\n",
        " \"\"\"\n",
        "is_grounded_on_facts_prompt = PromptTemplate(\n",
        "    template=is_grounded_on_facts_prompt_template,\n",
        "    input_variables=[\"context\", \"answer\"],\n",
        "    partial_variables={\"format_instructions\": grounded_on_facts_parser.get_format_instructions()},\n",
        ")\n",
        "is_grounded_on_facts_chain = is_grounded_on_facts_prompt | is_grounded_on_facts_llm | grounded_on_facts_parser\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LLM chain to determine if a question can be fully answered given a context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "can_be_answered_prompt_template = \"\"\"You receive a query: {question} and a context: {context}. \n",
        "You need to determine if the question can be fully answered based on the context.\n",
        "{format_instructions}\n",
        "\"\"\"\n",
        "\n",
        "class QuestionAnswer(BaseModel):\n",
        "    can_be_answered: bool = Field(description=\"binary result of whether the question can be fully answered or not\")\n",
        "    explanation: str = Field(description=\"An explanation of why the question can be fully answered or not.\")\n",
        "\n",
        "can_be_answered_json_parser = JsonOutputParser(pydantic_object=QuestionAnswer)\n",
        "\n",
        "answer_question_prompt = PromptTemplate(\n",
        "    template=can_be_answered_prompt_template,\n",
        "    input_variables=[\"question\",\"context\"],\n",
        "    partial_variables={\"format_instructions\": can_be_answered_json_parser.get_format_instructions()},\n",
        ")\n",
        "\n",
        "can_be_answered_llm = ChatGroq(temperature=0, model_name=\"llama3-70b-8192\", groq_api_key=groq_api_key, max_tokens=4000)\n",
        "can_be_answered_chain = answer_question_prompt | can_be_answered_llm | can_be_answered_json_parser\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### function to check both cases - hallucination and full answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "def grade_generation_v_documents_and_question(state):\n",
        "    \"\"\"Determines if the answer to the question is grounded in the facts.\"\"\"\n",
        "    print(\"Checking if the answer is grounded in the facts...\")\n",
        "    context = state[\"context\"]\n",
        "    answer = state[\"answer\"]\n",
        "    question = state[\"question\"]\n",
        "    \n",
        "    result = is_grounded_on_facts_chain.invoke({\"context\": context, \"answer\": answer})\n",
        "    grounded_on_facts = result[\"grounded_on_facts\"]\n",
        "    if not grounded_on_facts:\n",
        "        print(\"The answer is hallucination.\")\n",
        "        return \"hallucination\"\n",
        "    else:\n",
        "        print(\"The answer is grounded in the facts.\")\n",
        "\n",
        "        input_data = {\n",
        "            \"question\": question,\n",
        "            \"context\": context\n",
        "        }\n",
        "\n",
        "        # Invoke the chain to determine if the question can be answered\n",
        "        print(\"Determining if the question is fully answered...\")\n",
        "        output = can_be_answered_chain.invoke(input_data)\n",
        "        can_be_answered = output[\"can_be_answered\"]\n",
        "        if can_be_answered == True:\n",
        "            print(\"The question can be fully answered.\")\n",
        "            return \"useful\"\n",
        "        else:\n",
        "            print(\"The question cannot be fully answered.\")\n",
        "            return \"not_useful\"\n",
        "     "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test a pipeline of all parts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "init_state = {\"question\": \"who is harry?\"}\n",
        "context_state = retrieve_context_per_question(init_state)\n",
        "relevant_content_state = keep_only_relevant_content(context_state)\n",
        "is_relevant_content_state = is_relevant_content(relevant_content_state)\n",
        "answer_state = answer_question_from_context(relevant_content_state)\n",
        "final_answer = grade_generation_v_documents_and_question(answer_state)\n",
        "print(final_answer[\"answer\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build the Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GraphState(TypedDict):\n",
        "    \"\"\"\n",
        "    Represents the state of our graph.\n",
        "\n",
        "    Attributes:\n",
        "        question: question\n",
        "        context: context\n",
        "        answer: answer\n",
        "    \"\"\"\n",
        "\n",
        "    question: str\n",
        "    context: str\n",
        "    answer: str\n",
        "\n",
        "workflow = StateGraph(GraphState)\n",
        "\n",
        "# Define the nodes\n",
        "workflow.add_node(\"retrieve_context_per_question\",retrieve_context_per_question)\n",
        "workflow.add_node(\"keep_only_relevant_content\",keep_only_relevant_content)\n",
        "workflow.add_node(\"rewrite_question\",rewrite_question)\n",
        "workflow.add_node(\"answer_question_from_context\",answer_question_from_context)\n",
        "\n",
        "# Build the graph\n",
        "workflow.set_entry_point(\"retrieve_context_per_question\")\n",
        "workflow.add_edge(\"retrieve_context_per_question\", \"keep_only_relevant_content\")\n",
        "workflow.add_conditional_edges(\n",
        "    \"keep_only_relevant_content\",\n",
        "    is_relevant_content,\n",
        "    {\"relevant\":\"answer_question_from_context\",\n",
        "      \"not relevant\":\"rewrite_question\"},\n",
        "    )\n",
        "workflow.add_edge(\"rewrite_question\", \"retrieve_context_per_question\")\n",
        "workflow.add_conditional_edges(\n",
        "\"answer_question_from_context\",\n",
        "grade_generation_v_documents_and_question,\n",
        "{\"hallucination\":\"answer_question_from_context\",\n",
        "\"not_useful\":\"rewrite_question\",\n",
        "\"useful\":END},\n",
        "\n",
        ")\n",
        "\n",
        "retrival_app = workflow.compile()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/jpeg": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(\n",
        "    Image(\n",
        "        retrival_app.get_graph().draw_mermaid_png(\n",
        "            draw_method=MermaidDrawMethod.API,\n",
        "        )\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_retrieval_graph(question: str):\n",
        "    inputs = {\"question\": question}\n",
        "    for output in retrival_app.stream(inputs):\n",
        "        for key, value in output.items():\n",
        "            pass  # Node\n",
        "            # ... (your existing code)\n",
        "        pprint(\"--------------------\")\n",
        "    print(value)\n",
        "    return AIMessage(\n",
        "        content=value,  # The actual answer\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# tools = [\n",
        "#     Tool(\n",
        "#         name = \"retrieval_graph\",\n",
        "#         description=\"A graph that retrieves relevant information from a vector store based on a given question.\",\n",
        "#         func = lambda query: run_retrieval_graph(query),\n",
        "#     )\n",
        "# ]\n",
        "\n",
        "### TODO: the tools below is for debugging only, change it to the above tools\n",
        "\n",
        "def run_retrieve_context(question: str):\n",
        "    inputs = {\"question\": question}\n",
        "    state = retrieve_context_per_question(inputs)\n",
        "    return state\n",
        "tools = [\n",
        "Tool(\n",
        "    name=\"run_retrieve_context\",\n",
        "    func=lambda question: run_retrieve_context(question),\n",
        "    description=\"Retrieves relevant documents based on a given question.\",\n",
        "),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m System Message \u001b[0m================================\n",
            "\n",
            "You are a helpful assistant.\n",
            "\n",
            "=============================\u001b[1m Messages Placeholder \u001b[0m=============================\n",
            "\n",
            "\u001b[33;1m\u001b[1;3m{{messages}}\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.llms.openai import OpenAI\n",
        "\n",
        "prompt = hub.pull(\"wfh/react-agent-executor\")\n",
        "prompt.pretty_print()\n",
        "\n",
        "\n",
        "\n",
        "class Response(BaseModel):\n",
        "    \"\"\"Response to user.\"\"\"\n",
        "\n",
        "    response: str = Field(description=\"Response to user.\")\n",
        "\n",
        "response_parser = JsonOutputParser(pydantic_object=Response)\n",
        "\n",
        "# Choose the LLM that will drive the agent\n",
        "model_name = \"gpt-3.5-turbo-0125\"  # Specify LLM model\n",
        "agent_llm = ChatOpenAI(temperature=0, model=model_name, max_tokens=2000)  # Create LLM instance\n",
        "# agent_llm = ChatGroq(temperature=0, model_name=\"llama3-70b-8192\", groq_api_key=groq_api_key, max_tokens=2000)\n",
        "agent_executor = create_react_agent(agent_llm, tools, messages_modifier=prompt) \n",
        "\n",
        "# llm = ChatOpenAI(model=\"gpt-4-turbo-preview\")\n",
        "# agent_executor = create_react_agent(llm, tools, messages_modifier=prompt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "class PlanExecute(TypedDict):\n",
        "    input: str\n",
        "    anonymized_input: str\n",
        "    plan: List[str]\n",
        "    past_steps: Annotated[List[Tuple], operator.add]\n",
        "    response: str\n",
        "    mapping: dict "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Plan(BaseModel):\n",
        "    \"\"\"Plan to follow in future\"\"\"\n",
        "\n",
        "    steps: List[str] = Field(\n",
        "        description=\"different steps to follow, should be in sorted order\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GetPlan(BaseModel):\n",
        "    \"\"\"Possible results of the action.\"\"\"\n",
        "    plan: Plan = Field(description=\"Plan to follow in future.\")\n",
        "    explanation: str = Field(description=\"Explanation of the action.\")\n",
        "\n",
        "get_plan_parser = JsonOutputParser(pydantic_object=GetPlan)\n",
        "\n",
        "\n",
        "planner_prompt =\"\"\" For the given query {input}, come up with a simple step by step plan of how to figure out the answer. \n",
        "all you have is access to ONE function that retrieves both vector stores of chunks of a book and vector stores of the same book chapter summaries.\n",
        "any call to this function will retrive both the chunks and the chapter summaries. \n",
        "the function name is \"run_retrieve_context\", and you can use only this function to retrieve the information you need. \n",
        "so the plan should contain steps of different information you need to retrieve from the vector stores to answer the query.\n",
        "\n",
        "This plan should involve individual tasks, that if executed correctly will yield the correct answer. Do not add any superfluous steps. \n",
        "The result of the final step should be the final answer. Make sure that each step has all the information needed - do not skip steps.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "planner_prompt = PromptTemplate(\n",
        "    template=planner_prompt,\n",
        "      input_variables=[\"input\"], \n",
        "     )\n",
        "\n",
        "planner_llm = ChatGroq(temperature=0, model_name=\"llama3-70b-8192\", groq_api_key=groq_api_key, max_tokens=2000) \n",
        "\n",
        "planner = planner_prompt | planner_llm.with_structured_output(Plan)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "question = {\"input\": \"how did harry beat quirrell?\"}\n",
        "my_plan = planner.invoke(question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Plan(steps=[\"Search the vector store of chunks from the book for mentions of 'Harry' and 'Quirrell' to identify relevant passages.\", 'Extract the relevant passages and analyze them to understand the context of the interaction between Harry and Quirrell.', 'Identify the specific event or situation in which Harry beats Quirrell.', 'Extract the details of how Harry beats Quirrell from the relevant passage.', 'Compile the extracted details into a concise step-by-step plan.'])"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "my_plan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Response(BaseModel):\n",
        "    \"\"\"Response to user.\"\"\"\n",
        "\n",
        "    response: str\n",
        "\n",
        "\n",
        "class ActPossibleResults(BaseModel):\n",
        "    \"\"\"Possible results of the action.\"\"\"\n",
        "    response: Response = Field(description=\"Response to user.\")\n",
        "    plan: Plan = Field(description=\"Plan to follow in future.\")\n",
        "    explanation: str = Field(description=\"Explanation of the action.\")\n",
        "    \n",
        "\n",
        "act_possible_results_parser = JsonOutputParser(pydantic_object=ActPossibleResults)\n",
        "\n",
        "\n",
        "# replanner_prompt_template = \"\"\"you have no prior information about the question. all you have is access to a vector store of chunks from some book and a vector store of the same book chapter summaries.\n",
        "# you don't know what book it is and cannot rely on any prior knowledge of that book even if you realize what book it is.\n",
        "#     For the given objective, come up with a simple step by step plan. \\\n",
        "# This plan should involve individual tasks, that if executed correctly will yield the correct answer. Do not add any superfluous steps. \\\n",
        "# The result of the final step should be the final answer. Make sure that each step has all the information needed - do not skip steps.\n",
        "\n",
        "\n",
        "replanner_prompt_template =\"\"\" For the given objective, come up with a simple step by step plan of how to figure out the answer. \\\n",
        "all you have is access to ONE function that retrieves both vector stores of chunks of a book and vector stores of the same book chapter summaries. \n",
        "the function name is \"run_retrieve_context\", and you can use only this function to retrieve the information you need.\n",
        "so the plan should contain steps of different information you need to retrieve from the vector stores to answer the query.\n",
        "\n",
        "This plan should involve individual tasks, that if executed correctly will yield the correct answer. Do not add any superfluous steps. \\\n",
        "The result of the final step should be the final answer. Make sure that each step has all the information needed - do not skip steps.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Your objective was this:\n",
        "{input}\n",
        "\n",
        "Your original plan was this:\n",
        "{plan}\n",
        "\n",
        "You have currently done the follow steps:\n",
        "{past_steps}\n",
        "\n",
        "Update your plan accordingly. If no more steps are needed and you can return to the user,\n",
        "then respond with only the final answer. If further steps are needed, fill out the plan with only those steps.\n",
        "Do not return previously done steps as part of the plan.\n",
        "\n",
        "the format is json so escape quotes and new lines.\n",
        "\n",
        "{format_instructions}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "replanner_prompt = PromptTemplate(\n",
        "    template=replanner_prompt_template,\n",
        "    input_variables=[\"input\", \"plan\", \"past_steps\"],\n",
        "    partial_variables={\"format_instructions\": act_possible_results_parser.get_format_instructions()},\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "replanner = replanner_prompt | ChatGroq(temperature=0, model_name=\"llama3-70b-8192\", groq_api_key=groq_api_key, max_tokens=2000) | act_possible_results_parser\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AnonymizeQuestion(BaseModel):\n",
        "    \"\"\"Anonymized question and mapping.\"\"\"\n",
        "    anonymize_question : str = Field(description=\"Anonymized question.\")\n",
        "    mapping: dict = Field(description=\"Mapping of original words to variables.\")\n",
        "    explanation: str = Field(description=\"Explanation of the action.\")\n",
        "\n",
        "anonymize_question_parser = JsonOutputParser(pydantic_object=AnonymizeQuestion)\n",
        "\n",
        "\n",
        "anonymize_question_prompt_template = \"\"\" You are a question anonymizer. The input You receive is a string containing several words that\n",
        " construct a question {input}. Your goal is to changes all name entities in the input strings to variables. keep those variables\n",
        "in the mapping dictionary do it here, don't write a code that does this. .just output the anonymized_question and mapping dictionary in this format: {format_instructions}\"\"\"\n",
        "\n",
        "\n",
        "anonymize_question_prompt = PromptTemplate(\n",
        "    template=anonymize_question_prompt_template,\n",
        "    input_variables=[\"input\"],\n",
        "    partial_variables={\"format_instructions\": anonymize_question_parser.get_format_instructions()},\n",
        ")\n",
        "\n",
        "anonymize_question_llm = ChatGroq(temperature=0, model_name=\"llama3-70b-8192\", groq_api_key=groq_api_key, max_tokens=2000)\n",
        "anonymize_question_chain = anonymize_question_prompt | anonymize_question_llm | anonymize_question_parser\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DeAnonymizePlan(BaseModel):\n",
        "    \"\"\"Possible results of the action.\"\"\"\n",
        "    plan: List = Field(description=\"Plan to follow in future.\")\n",
        "    explanation: str = Field(description=\"Explanation of the action.\")\n",
        "\n",
        "deanonymize_plan_parser = JsonOutputParser(pydantic_object=DeAnonymizePlan)\n",
        "\n",
        "\n",
        "de_anonymize_plan_prompt_template = \"\"\" you receive a list of tasks: {plan}, where some of the words are replaced with mapped variables. you also receive\n",
        " the mapping for those variables to words {mapping}. you should create the new list of tasks, where all the mapped variables are now their mapped words. do it here, don't write a code that does this.\n",
        " {format_instructions}\"\"\"\n",
        "\n",
        "\n",
        "de_anonymize_plan_prompt = PromptTemplate(\n",
        "    template=de_anonymize_plan_prompt_template,\n",
        "    input_variables=[\"plan\", \"mapping\"],\n",
        "    partial_variables={\"format_instructions\": deanonymize_plan_parser.get_format_instructions()},\n",
        ")\n",
        "\n",
        "de_anonymize_plan_llm = ChatGroq(temperature=0, model_name=\"llama3-70b-8192\", groq_api_key=groq_api_key, max_tokens=2000)\n",
        "de_anonymize_plan_chain = de_anonymize_plan_prompt | de_anonymize_plan_llm | deanonymize_plan_parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "anonimized_querry: how did X beat Y?\n"
          ]
        }
      ],
      "source": [
        "state1 = {'input': \"how did harry beat quirrell?\"}\n",
        "anonymized_question_output = anonymize_question_chain.invoke(state1)\n",
        "anonymized_question = anonymized_question_output[\"anonymize_question\"]\n",
        "mapping = anonymized_question_output[\"mapping\"]\n",
        "print(f'anonimized_querry: {anonymized_question}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'how did X beat Y?'"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "anonymized_question\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'X': 'Harry', 'Y': 'Quirrell'}"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Plan(steps=['Retrieve chapter summaries related to X and Y from vector stores', 'Retrieve vector stores of chunks from the book related to X and Y', 'Compare the information from the chapter summaries and vector stores to identify the key events or circumstances that led to X beating Y', 'Organize the key events or circumstances in a step-by-step manner to create a simple plan of how X beat Y'])"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "plan = planner.invoke({\"input\": anonymized_question})\n",
        "plan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Determine the context of X and Y',\n",
              " 'Identify the competition or event where X beat Y',\n",
              " 'Research the details of the event',\n",
              " \"Analyze the factors that contributed to X's victory\"]"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "plan.steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [],
      "source": [
        "deanonimzed_plan = de_anonymize_plan_chain.invoke({\"plan\": plan.steps, \"mapping\": mapping})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'plan': ['Determine the context of Harry and Quirrell',\n",
              "  'Identify the competition or event where Harry beat Quirrell',\n",
              "  'Research the details of the event',\n",
              "  \"Analyze the factors that contributed to Harry's victory\"],\n",
              " 'explanation': \"This plan outlines the steps to understand the context and circumstances of Harry's victory over Quirrell.\"}"
            ]
          },
          "execution_count": 115,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "deanonimzed_plan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Literal\n",
        "\n",
        "\n",
        "def execute_step(state: PlanExecute):\n",
        "    print(\"Executing step\")\n",
        "    plan = state[\"plan\"]\n",
        "    plan_str = \"\\n\".join(f\"{i+1}. {step}\" for i, step in enumerate(plan))\n",
        "    task = plan[0]\n",
        "    task_formatted = f\"\"\"For the following plan:\n",
        "{plan_str}\\n\\nYou are tasked with executing step {1}, {task}.\"\"\"\n",
        "    print(f'task_formatted: {task_formatted}')\n",
        "    agent_response = agent_executor.invoke(\n",
        "        {\"messages\": [(\"user\", task_formatted)]}\n",
        "    )\n",
        "    print(f'agent_response: {agent_response}')\n",
        "    return {\n",
        "        \"past_steps\": (task, agent_response[\"messages\"][-1].content),\n",
        "    }\n",
        "\n",
        "def anonymize_queries(state: PlanExecute):\n",
        "    print(\"Anonymizing question\")\n",
        "    anonymized_question_output = anonymize_question_chain.invoke(state['input'])\n",
        "    anonymized_question = anonymized_question_output[\"anonymize_question\"]\n",
        "    mapping = anonymized_question_output[\"mapping\"]\n",
        "    return {\"anonymized_input\": anonymized_question, \"mapping\": mapping}\n",
        "\n",
        "def deanonymize_queries(state: PlanExecute):\n",
        "    print(\"De-anonymizing plan\")\n",
        "    deanonimzed_plan = de_anonymize_plan_chain.invoke({\"plan\": state[\"plan\"], \"mapping\": state[\"mapping\"]})\n",
        "    return {\"plan\": deanonimzed_plan[\"plan\"]}\n",
        "\n",
        "\n",
        "def plan_step(state: PlanExecute):\n",
        "    print(\"Planning step\")\n",
        "    # plan = planner.invoke({\"messages\": [(\"user\", state['anonymized_input'])]})\n",
        "    plan = planner.invoke({\"input\": state['anonymized_input']})\n",
        "\n",
        "    return {\"plan\": plan.steps}\n",
        "\n",
        "\n",
        "def replan_step(state: PlanExecute):\n",
        "    print(\"Replanning step\")\n",
        "    state = format_state_past_steps(state)\n",
        "    state = clean_empty_fields_dictionary(state)\n",
        "    print(\"state:\")\n",
        "    print(state)\n",
        "    output =  replanner.invoke(state)\n",
        "    return process_replanner_output(output)\n",
        "  \n",
        "\n",
        "def should_end(state: PlanExecute) -> Literal[\"agent\", \"__end__\"]:\n",
        "    print(\"Checking if should end\")\n",
        "    if \"response\" in state and state[\"response\"]:\n",
        "        return \"__end__\"\n",
        "    else:\n",
        "        return \"agent\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph\n",
        "\n",
        "agent_workflow = StateGraph(PlanExecute)\n",
        "\n",
        "# Add the anonymize node\n",
        "agent_workflow.add_node(\"anonymize\", anonymize_queries)\n",
        "# Add the plan node\n",
        "agent_workflow.add_node(\"planner\", plan_step)\n",
        "# Add the deanonymize node\n",
        "agent_workflow.add_node(\"de-anonymize\", deanonymize_queries)\n",
        "\n",
        "\n",
        "# Add the execution step\n",
        "agent_workflow.add_node(\"agent\", execute_step)\n",
        "\n",
        "# Add a replan node\n",
        "agent_workflow.add_node(\"replan\", replan_step)\n",
        "\n",
        "\n",
        "agent_workflow.set_entry_point(\"anonymize\")\n",
        "\n",
        "# From anonymize we go to plan\n",
        "agent_workflow.add_edge(\"anonymize\", \"planner\")\n",
        "\n",
        "# From plan we go to deanonymize\n",
        "agent_workflow.add_edge(\"planner\", \"de-anonymize\")\n",
        "\n",
        "# From deanonymize we go to agent\n",
        "agent_workflow.add_edge(\"de-anonymize\", \"agent\")\n",
        "\n",
        "# From agent, we replan\n",
        "agent_workflow.add_edge(\"agent\", \"replan\")\n",
        "\n",
        "agent_workflow.add_conditional_edges(\n",
        "    \"replan\",\n",
        "    # Next, we pass in the function that will determine which node is called next.\n",
        "    should_end,\n",
        ")\n",
        "\n",
        "# Finally, we compile it!\n",
        "# This compiles it into a LangChain Runnable,\n",
        "# meaning you can use it as you would any other runnable\n",
        "plan_and_execute_app = agent_workflow.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/jpeg": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "display(Image(plan_and_execute_app.get_graph(xray=True).draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def execute_plan_and_print_steps(inputs, recursion_limit=3):\n",
        "#     config = {\"recursion_limit\": recursion_limit}\n",
        "#     for plan_output in plan_and_execute_app.stream(inputs, config=config):\n",
        "#         for agent_state_key, agent_state_value in plan_output.items():\n",
        "#             print(f' curr step: {agent_state_value}')\n",
        "#             pass  # Node\n",
        "#             # ... (your existing code)\n",
        "#         pprint(\"--------------------\")\n",
        "#     return agent_state_value['response']\n",
        "\n",
        "def execute_plan_and_print_steps(inputs, recursion_limit=20):\n",
        "    config = {\"recursion_limit\": recursion_limit}\n",
        "    try:    \n",
        "        for plan_output in plan_and_execute_app.stream(inputs, config=config):\n",
        "            for agent_state_key, agent_state_value in plan_output.items():\n",
        "                print(f' curr step: {agent_state_value}')\n",
        "        return plan_output  # Return the final output if found\n",
        "    except langgraph.pregel.GraphRecursionError:\n",
        "        print(\"The answer wasn't found in the data.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Anonymizing question\n",
            " curr step: {'anonymized_input': 'who is X?.', 'mapping': {'X': 'charles darwin'}}\n",
            "Planning step\n",
            " curr step: {'plan': ['Retrieve book chunks and chapter summaries using run_retrieve_context function', 'Extract relevant information from chunks and chapter summaries to identify X', 'Analyze extracted information to determine who X is', 'Return the answer to the query: who is X?']}\n",
            "De-anonymizing plan\n",
            " curr step: {'plan': ['Retrieve book chunks and chapter summaries using run_retrieve_context function', 'Extract relevant information from chunks and chapter summaries to identify charles darwin', 'Analyze extracted information to determine who charles darwin is', 'Return the answer to the query: who is charles darwin?']}\n",
            "The answer wasn't found in the data.\n",
            "The final answer is: None\n"
          ]
        }
      ],
      "source": [
        "inputs = {\"input\": \"who is charles darwin?\"}\n",
        "final_answer = execute_plan_and_print_steps(inputs)\n",
        "print(f'The final answer is: {final_answer}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Anonymizing question\n",
            " curr step: {'anonymized_input': 'how did X beat Y?', 'mapping': {'X': 'Harry', 'Y': 'Quirrell'}}\n",
            "'--------------------'\n",
            "Planning step\n",
            " curr step: {'plan': ['Retrieve context for the book using run_retrieve_context function', 'Extract relevant chunks and chapter summaries related to X and Y', 'Analyze the extracted information to identify the key factors that contributed to X beating Y', \"Determine the specific actions or events that led to X's victory\", 'Organize the findings into a clear and concise answer to the original query']}\n",
            "'--------------------'\n",
            "De-anonymizing plan\n",
            " curr step: {'plan': ['Retrieve context for the book using run_retrieve_context function', 'Extract relevant chunks and chapter summaries related to Harry and Quirrell', 'Analyze the extracted information to identify the key factors that contributed to Harry beating Quirrell', \"Determine the specific actions or events that led to Harry's victory\", 'Organize the findings into a clear and concise answer to the original query']}\n",
            "'--------------------'\n",
            "Executing step\n",
            "task_formatted: For the following plan:\n",
            "1. Retrieve context for the book using run_retrieve_context function\n",
            "2. Extract relevant chunks and chapter summaries related to Harry and Quirrell\n",
            "3. Analyze the extracted information to identify the key factors that contributed to Harry beating Quirrell\n",
            "4. Determine the specific actions or events that led to Harry's victory\n",
            "5. Organize the findings into a clear and concise answer to the original query\n",
            "\n",
            "You are tasked with executing step 1, Retrieve context for the book using run_retrieve_context function.\n",
            "Retrieving relevant chunks...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\N7\\PycharmProjects\\llm_tasks\\RAG-Harry-Potter\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieving relevant chapter summaries...\n",
            "agent_response: {'messages': [HumanMessage(content=\"For the following plan:\\n1. Retrieve context for the book using run_retrieve_context function\\n2. Extract relevant chunks and chapter summaries related to Harry and Quirrell\\n3. Analyze the extracted information to identify the key factors that contributed to Harry beating Quirrell\\n4. Determine the specific actions or events that led to Harry's victory\\n5. Organize the findings into a clear and concise answer to the original query\\n\\nYou are tasked with executing step 1, Retrieve context for the book using run_retrieve_context function.\", id='19938e05-e51d-472b-87d6-6baab12592fa'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_QMRA3tOcAVHNKePWxB5I57OR', 'function': {'arguments': '{\"__arg1\":\"Harry Potter and the Sorcerer\\'s Stone\"}', 'name': 'run_retrieve_context'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 172, 'total_tokens': 197}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-4870b22e-aef0-483e-b17a-a9c923448540-0', tool_calls=[{'name': 'run_retrieve_context', 'args': {'__arg1': \"Harry Potter and the Sorcerer's Stone\"}, 'id': 'call_QMRA3tOcAVHNKePWxB5I57OR'}]), ToolMessage(content='{\"context\": \"HP 1 - Harry Potter and the\\\\nSorcerer\\\\\\\\\\'s StoneIn Chapter Thirteen of Harry Potter and the Sorcerer\\\\\\\\\\'s Stone, Harry is haunted by nightmares of his parents\\\\\\\\\\' death and the mysterious figure he saw in the Mirror of Erised. He, Ron, and Hermione continue their search for Nicolas Flamel, the maker of the Sorcerer\\\\\\\\\\'s Stone, and finally discover that Flamel is the only one who possesses the stone, which has the power to turn metal into gold and grant immortality.\\\\nMeanwhile, Quidditch practice intensifies as Gryffindor prepares for a crucial match against Hufflepuff. However, tensions rise as Snape is appointed as the referee, leading to concerns about biased officiating. Harry is determined to play in the match despite his fears of Snape\\\\\\\\\\'s intentions.\\\\nDuring the match, Harry catches the Golden Snitch in record time, securing Gryffindor\\\\\\\\\\'s victory and putting them in the lead for the house championship. Dumbledore congratulates Harry, and Snape appears visibly angry. Later, Harry witnesses Snape meeting with Quirrell in the Forbidden Forest, discussing the Sorcerer\\\\\\\\\\'s Stone and the obstacles guarding it.\\\\nHarry shares this information with Ron and Hermione, realizing that Snape is trying to force Quirrell to help him obtain the Stone. They fear that the Stone is only safe as long as Quirrell resists Snape\\\\\\\\\\'s influence. The chapter ends with the ominous realization that the Stone may not be safe for long. (Chapter 13)\", \"question\": \"Harry Potter and the Sorcerer\\'s Stone\"}', name='run_retrieve_context', id='a943ab43-f1f9-48fe-af41-6007c42cf0be', tool_call_id='call_QMRA3tOcAVHNKePWxB5I57OR'), AIMessage(content='The context retrieved for \"Harry Potter and the Sorcerer\\'s Stone\" is from Chapter Thirteen. In this chapter, Harry is haunted by nightmares of his parents\\' death and the mysterious figure he saw in the Mirror of Erised. He, Ron, and Hermione continue their search for Nicolas Flamel, the maker of the Sorcerer\\'s Stone, and discover that Flamel is the only one who possesses the stone, which has the power to turn metal into gold and grant immortality.\\n\\nMeanwhile, tensions rise as Gryffindor prepares for a crucial Quidditch match against Hufflepuff, with Snape appointed as the referee, leading to concerns about biased officiating. Harry catches the Golden Snitch in record time during the match, securing Gryffindor\\'s victory and putting them in the lead for the house championship. Dumbledore congratulates Harry, and Snape appears visibly angry.\\n\\nLater, Harry witnesses Snape meeting with Quirrell in the Forbidden Forest, discussing the Sorcerer\\'s Stone and the obstacles guarding it. Harry shares this information with Ron and Hermione, realizing that Snape is trying to force Quirrell to help him obtain the Stone. They fear that the Stone is only safe as long as Quirrell resists Snape\\'s influence, raising concerns about the Stone\\'s safety.\\n\\nThis context provides insights into the events leading up to Harry\\'s victory and the challenges he faces in the pursuit of the Sorcerer\\'s Stone.', response_metadata={'token_usage': {'completion_tokens': 288, 'prompt_tokens': 543, 'total_tokens': 831}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-4481c382-59f2-499c-939d-c22693044eef-0')]}\n",
            " curr step: {'past_steps': ('Retrieve context for the book using run_retrieve_context function', 'The context retrieved for \"Harry Potter and the Sorcerer\\'s Stone\" is from Chapter Thirteen. In this chapter, Harry is haunted by nightmares of his parents\\' death and the mysterious figure he saw in the Mirror of Erised. He, Ron, and Hermione continue their search for Nicolas Flamel, the maker of the Sorcerer\\'s Stone, and discover that Flamel is the only one who possesses the stone, which has the power to turn metal into gold and grant immortality.\\n\\nMeanwhile, tensions rise as Gryffindor prepares for a crucial Quidditch match against Hufflepuff, with Snape appointed as the referee, leading to concerns about biased officiating. Harry catches the Golden Snitch in record time during the match, securing Gryffindor\\'s victory and putting them in the lead for the house championship. Dumbledore congratulates Harry, and Snape appears visibly angry.\\n\\nLater, Harry witnesses Snape meeting with Quirrell in the Forbidden Forest, discussing the Sorcerer\\'s Stone and the obstacles guarding it. Harry shares this information with Ron and Hermione, realizing that Snape is trying to force Quirrell to help him obtain the Stone. They fear that the Stone is only safe as long as Quirrell resists Snape\\'s influence, raising concerns about the Stone\\'s safety.\\n\\nThis context provides insights into the events leading up to Harry\\'s victory and the challenges he faces in the pursuit of the Sorcerer\\'s Stone.')}\n",
            "'--------------------'\n",
            "Replanning step\n",
            "state:\n",
            "{'input': 'how did harry beat quirrell?', 'anonymized_input': 'how did X beat Y?', 'plan': ['Retrieve context for the book using run_retrieve_context function', 'Extract relevant chunks and chapter summaries related to Harry and Quirrell', 'Analyze the extracted information to identify the key factors that contributed to Harry beating Quirrell', \"Determine the specific actions or events that led to Harry's victory\", 'Organize the findings into a clear and concise answer to the original query'], 'past_steps': 'Retrieve context for the book using run_retrieve_context function\\nThe context retrieved for \"Harry Potter and the Sorcerer\\'s Stone\" is from Chapter Thirteen. In this chapter, Harry is haunted by nightmares of his parents\\' death and the mysterious figure he saw in the Mirror of Erised. He, Ron, and Hermione continue their search for Nicolas Flamel, the maker of the Sorcerer\\'s Stone, and discover that Flamel is the only one who possesses the stone, which has the power to turn metal into gold and grant immortality.\\n\\nMeanwhile, tensions rise as Gryffindor prepares for a crucial Quidditch match against Hufflepuff, with Snape appointed as the referee, leading to concerns about biased officiating. Harry catches the Golden Snitch in record time during the match, securing Gryffindor\\'s victory and putting them in the lead for the house championship. Dumbledore congratulates Harry, and Snape appears visibly angry.\\n\\nLater, Harry witnesses Snape meeting with Quirrell in the Forbidden Forest, discussing the Sorcerer\\'s Stone and the obstacles guarding it. Harry shares this information with Ron and Hermione, realizing that Snape is trying to force Quirrell to help him obtain the Stone. They fear that the Stone is only safe as long as Quirrell resists Snape\\'s influence, raising concerns about the Stone\\'s safety.\\n\\nThis context provides insights into the events leading up to Harry\\'s victory and the challenges he faces in the pursuit of the Sorcerer\\'s Stone.', 'mapping': {'X': 'Harry', 'Y': 'Quirrell'}}\n",
            "Checking if should end\n",
            " curr step: {'plan': [\"Extract relevant chunks and chapter summaries related to Harry and Quirrell's final confrontation\", 'Analyze the extracted information to identify the key factors that contributed to Harry beating Quirrell', \"Determine the specific actions or events that led to Harry's victory\"]}\n",
            "'--------------------'\n",
            "Executing step\n",
            "task_formatted: For the following plan:\n",
            "1. Extract relevant chunks and chapter summaries related to Harry and Quirrell's final confrontation\n",
            "2. Analyze the extracted information to identify the key factors that contributed to Harry beating Quirrell\n",
            "3. Determine the specific actions or events that led to Harry's victory\n",
            "\n",
            "You are tasked with executing step 1, Extract relevant chunks and chapter summaries related to Harry and Quirrell's final confrontation.\n",
            "Retrieving relevant chunks...\n",
            "Retrieving relevant chapter summaries...\n",
            "Retrieving relevant chunks...Retrieving relevant chunks...\n",
            "\n",
            "Retrieving relevant chapter summaries...\n",
            "Retrieving relevant chapter summaries...\n",
            "agent_response: {'messages': [HumanMessage(content=\"For the following plan:\\n1. Extract relevant chunks and chapter summaries related to Harry and Quirrell's final confrontation\\n2. Analyze the extracted information to identify the key factors that contributed to Harry beating Quirrell\\n3. Determine the specific actions or events that led to Harry's victory\\n\\nYou are tasked with executing step 1, Extract relevant chunks and chapter summaries related to Harry and Quirrell's final confrontation.\", id='a12168bd-0f96-40b7-b402-2f79ef7727de'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_P8yr2Uz9DiW4WK8ivYAMN2Nt', 'function': {'arguments': '{\"__arg1\":\"Harry and Quirrell\\'s final confrontation\"}', 'name': 'run_retrieve_context'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 149, 'total_tokens': 174}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-4205a108-1acd-45db-ad67-08efde0679d3-0', tool_calls=[{'name': 'run_retrieve_context', 'args': {'__arg1': \"Harry and Quirrell's final confrontation\"}, 'id': 'call_P8yr2Uz9DiW4WK8ivYAMN2Nt'}]), ToolMessage(content='{\"context\": \"as he could. Quirrell screamed and tried to throw Harry off \\\\u2014 the pain in\\\\nHarry\\\\u2019s head was building \\\\u2014 he couldn\\\\u2019t see \\\\u2014 he could only hear Quirrell\\\\u2019s\\\\nterrible shrieks and Voldemort\\\\u2019s yells of, \\\\u201cKILL HIM! KILL HIM!\\\\u201d and other\\\\nvoices, maybe in Harry\\\\u2019s own head, crying, \\\\u201cHarry! Harry!\\\\u201d\\\\n      He felt Quirrell\\\\u2019s arm wrenched from his grasp, knew all was lost, and\\\\nfell into blackness, down\\\\u2026down\\\\u2026 down\\\\u2026.\\\\n \\\\nSomething gold was glinting just above him. The Snitch! He tried to catch it,\\\\nbut his arms were too heavy.\\\\n      He blinked. It wasn\\\\u2019t the Snitch at all. It was a pair of glasses. How\\\\nstrange.\\\\n      He blinked again. The smiling face of Albus Dumbledore swam into\\\\nview above him.In Chapter Seventeen, titled \\\\\\\\\\\\\"The Man with Two Faces,\\\\\\\\\\\\\" Harry comes face to face with Professor Quirrell, who reveals himself to be the one trying to steal the Sorcerer\\\\\\\\\\'s Stone. Quirrell explains how he tried to kill Harry during the Quidditch match and how Snape was actually trying to save him. Quirrell also reveals that he is serving Lord Voldemort and that Voldemort is sharing his body. Harry manages to get the Stone from the Mirror of Erised by lying to Quirrell and keeping him distracted. Quirrell\\\\\\\\\\'s true form is revealed to be Voldemort\\\\\\\\\\'s face on the back of his head, and he tries to kill Harry but is unable to touch him due to the protection of his mother\\\\\\\\\\'s love. Dumbledore arrives in time to save Harry and stop Quirrell. The Stone is destroyed, and Dumbledore explains that Nicolas Flamel and his wife will die as a result. Harry receives points for his bravery and courage, tying Gryffindor with Slytherin for the house cup. The students leave Hogwarts for the summer, and Harry looks forward to having fun with Dudley without using magic. The chapter ends with Harry\\\\\\\\\\'s family, the Dursleys, picking him up from the train station. (Chapter 17)\", \"question\": \"Harry and Quirrell\\'s final confrontation\"}', name='run_retrieve_context', id='baa43881-0071-4b87-9fa4-79101b38c251', tool_call_id='call_P8yr2Uz9DiW4WK8ivYAMN2Nt'), AIMessage(content=\"I have extracted relevant chunks and a chapter summary related to Harry and Quirrell's final confrontation. Here is the information:\\n\\n- In the final confrontation, Harry faces Professor Quirrell, who is revealed to be serving Lord Voldemort and sharing his body.\\n- Quirrell tries to kill Harry but is unable to touch him due to the protection of his mother's love.\\n- Dumbledore arrives in time to save Harry and stop Quirrell.\\n- The Sorcerer's Stone is destroyed, and Dumbledore explains the consequences for Nicolas Flamel and his wife.\\n- Harry receives points for his bravery and courage, tying Gryffindor with Slytherin for the house cup.\\n- The chapter ends with Harry's family, the Dursleys, picking him up from the train station.\\n\\nNext, I will proceed with step 2 to analyze the extracted information to identify the key factors that contributed to Harry beating Quirrell.\", additional_kwargs={'tool_calls': [{'id': 'call_cWP13ZBLwf6JwoNOa2yfU4Ol', 'function': {'arguments': '{\"__arg1\": \"key factors that contributed to Harry beating Quirrell\"}', 'name': 'run_retrieve_context'}, 'type': 'function'}, {'id': 'call_ONrRZZE4CnC3EGZFp8YkDHf5', 'function': {'arguments': '{\"__arg1\": \"specific actions or events that led to Harry\\'s victory\"}', 'name': 'run_retrieve_context'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 255, 'prompt_tokens': 706, 'total_tokens': 961}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-547e97f6-bc1a-4093-9b19-2f9a0da9980e-0', tool_calls=[{'name': 'run_retrieve_context', 'args': {'__arg1': 'key factors that contributed to Harry beating Quirrell'}, 'id': 'call_cWP13ZBLwf6JwoNOa2yfU4Ol'}, {'name': 'run_retrieve_context', 'args': {'__arg1': \"specific actions or events that led to Harry's victory\"}, 'id': 'call_ONrRZZE4CnC3EGZFp8YkDHf5'}]), ToolMessage(content='{\"context\": \"\\\\u201cThat Quidditch Cup\\\\u2019ll have our name on it this year,\\\\u201d said Wood\\\\nhappily as they trudged back up to the castle. \\\\u201cI wouldn\\\\u2019t be surprised if you turn\\\\nout better than Charlie Weasley, and he could have played for England if he\\\\nhadn\\\\u2019t gone off chasing dragons.\\\\u201d\\\\n \\\\nPerhaps it was because he was now so busy, what with Quidditch practice\\\\nthree evenings a week on top of all his homework, but Harry could hardly\\\\nbelieve it when he realized that he\\\\u2019d already been at Hogwarts two months. The\\\\ncastle felt more like home than Privet Drive ever had. His lessons, too, were\\\\nbecoming more and more interesting now that they had mastered the basics.\\\\n      On Halloween morning they woke to the delicious smell of baking\\\\npumpkin wafting through the corridors. Even better, Professor Flitwick\\\\nannounced in Charms that he thought they were ready to start making objects fly,\\\\nsomething they had all been dying to try since they\\\\u2019d seen him make Neville\\\\u2019sIn Chapter Seventeen, titled \\\\\\\\\\\\\"The Man with Two Faces,\\\\\\\\\\\\\" Harry comes face to face with Professor Quirrell, who reveals himself to be the one trying to steal the Sorcerer\\\\\\\\\\'s Stone. Quirrell explains how he tried to kill Harry during the Quidditch match and how Snape was actually trying to save him. Quirrell also reveals that he is serving Lord Voldemort and that Voldemort is sharing his body. Harry manages to get the Stone from the Mirror of Erised by lying to Quirrell and keeping him distracted. Quirrell\\\\\\\\\\'s true form is revealed to be Voldemort\\\\\\\\\\'s face on the back of his head, and he tries to kill Harry but is unable to touch him due to the protection of his mother\\\\\\\\\\'s love. Dumbledore arrives in time to save Harry and stop Quirrell. The Stone is destroyed, and Dumbledore explains that Nicolas Flamel and his wife will die as a result. Harry receives points for his bravery and courage, tying Gryffindor with Slytherin for the house cup. The students leave Hogwarts for the summer, and Harry looks forward to having fun with Dudley without using magic. The chapter ends with Harry\\\\\\\\\\'s family, the Dursleys, picking him up from the train station. (Chapter 17)\", \"question\": \"key factors that contributed to Harry beating Quirrell\"}', name='run_retrieve_context', id='4d11946d-431e-484c-8e5d-016be70ab54f', tool_call_id='call_cWP13ZBLwf6JwoNOa2yfU4Ol'), ToolMessage(content='{\"context\": \"and hugging Parvati Patil in the row in front.\\\\n      Harry jumped off his broom, a foot from the ground. He couldn\\\\u2019t believe\\\\nit. He\\\\u2019d done it \\\\u2014 the game was over; it had barely lasted five minutes. As\\\\nGryffindors came spilling onto the field, he saw Snape land nearby, white-faced\\\\nand tight-lipped \\\\u2014 then Harry felt a hand on his shoulder and looked up into\\\\nDumbledore\\\\u2019s smiling face.\\\\n      \\\\u201cWell done,\\\\u201d said Dumbledore quietly, so that only Harry could hear.\\\\n\\\\u201cNice to see you haven\\\\u2019t been brooding about that mirror...been keeping\\\\nbusy...excellent...\\\\u201d\\\\n      Snape spat bitterly on the ground.\\\\n \\\\nHarry left the locker room alone some time later, to take his Nimbus Two\\\\nThousand back to the broomshed. He couldn\\\\u2019t ever remember feeling happier.\\\\nHe\\\\u2019d really done something to be proud of now \\\\u2013 no one could say he was just a\\\\nfamous name any more. The evening air had never smelled so sweet. He walked\\\\nover the damp grass, reliving the last hour in his head, which was a happy blur:In Chapter Sixteen of Harry Potter and the Sorcerer\\\\\\\\\\'s Stone, Harry, Ron, and Hermione are in the midst of their final exams at Hogwarts. Despite the looming threat of Voldemort, they manage to focus on their exams and complete them successfully. However, Harry is plagued by a recurring nightmare and a persistent pain in his scar.\\\\nAs they finish their exams, the trio relaxes by the lake, but Harry\\\\\\\\\\'s scar continues to bother him, signaling danger. Harry becomes increasingly convinced that Snape is planning to steal the Sorcerer\\\\\\\\\\'s Stone, and he rushes to Hagrid to confirm his suspicions. Hagrid inadvertently reveals that he unknowingly gave information about Fluffy, the three-headed dog guarding the Stone, to a stranger in a pub.\\\\nRealizing that Snape may be making a move that night, Harry, Ron, and Hermione set out to stop him. They navigate through various obstacles, including a giant squid, Peeves the poltergeist, and a series of enchantments guarding the Stone. They eventually find themselves in a chamber with a giant chessboard, where they must play a life-sized game of wizard\\\\\\\\\\'s chess to proceed.\\\\nAfter successfully navigating the chessboard, they encounter a troll and a series of potions that will help them pass through the final obstacles. Hermione figures out the logic puzzle presented by the potions, and Harry and Hermione each drink the correct potion to pass through the final challenges.\\\\nHermione successfully passes through the final obstacle and heads back to get help from Dumbledore, while Harry faces the final challenge alone. He confronts Snape, who is not alone but is accompanied by Quirrell, who is revealed to be working for Voldemort. Harry manages to thwart their plans and prevent them from obtaining the Sorcerer\\\\\\\\\\'s Stone.\\\\nIn the end, Harry emerges victorious, having faced his fears and overcome the challenges with the help of his friends. The chapter ends with Harry reflecting on the importance of friendship, bravery, and loyalty in the face of danger. (Chapter 16)\", \"question\": \"specific actions or events that led to Harry\\'s victory\"}', name='run_retrieve_context', id='0d36073c-3a7f-4a1d-8b28-e2ce726eaf7a', tool_call_id='call_ONrRZZE4CnC3EGZFp8YkDHf5'), AIMessage(content=\"I have retrieved the following information related to Harry beating Quirrell:\\n\\n### Key Factors that Contributed to Harry Beating Quirrell:\\n- Harry managed to get the Sorcerer's Stone from the Mirror of Erised by lying to Quirrell and keeping him distracted.\\n- Quirrell's true form was revealed to be Voldemort's face on the back of his head, and he was unable to touch Harry due to the protection of his mother's love.\\n- Dumbledore arrived in time to save Harry and stop Quirrell, contributing to Harry's victory.\\n\\n### Specific Actions or Events that Led to Harry's Victory:\\n- Harry successfully completed his final exams at Hogwarts despite the looming threat of Voldemort.\\n- Harry, Ron, and Hermione suspected Snape of planning to steal the Sorcerer's Stone and took action to stop him.\\n- They navigated through various obstacles, including a giant chessboard and a series of enchantments guarding the Stone.\\n- Harry confronted Snape and Quirrell, who was revealed to be working for Voldemort, and managed to thwart their plans and prevent them from obtaining the Sorcerer's Stone.\\n\\nThese actions and events played a crucial role in Harry's victory over Quirrell. If you need further analysis or information, feel free to let me know.\", response_metadata={'token_usage': {'completion_tokens': 257, 'prompt_tokens': 2229, 'total_tokens': 2486}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-af073924-8713-40c7-bdb9-f41beaa8ab4c-0')]}\n",
            " curr step: {'past_steps': (\"Extract relevant chunks and chapter summaries related to Harry and Quirrell's final confrontation\", \"I have retrieved the following information related to Harry beating Quirrell:\\n\\n### Key Factors that Contributed to Harry Beating Quirrell:\\n- Harry managed to get the Sorcerer's Stone from the Mirror of Erised by lying to Quirrell and keeping him distracted.\\n- Quirrell's true form was revealed to be Voldemort's face on the back of his head, and he was unable to touch Harry due to the protection of his mother's love.\\n- Dumbledore arrived in time to save Harry and stop Quirrell, contributing to Harry's victory.\\n\\n### Specific Actions or Events that Led to Harry's Victory:\\n- Harry successfully completed his final exams at Hogwarts despite the looming threat of Voldemort.\\n- Harry, Ron, and Hermione suspected Snape of planning to steal the Sorcerer's Stone and took action to stop him.\\n- They navigated through various obstacles, including a giant chessboard and a series of enchantments guarding the Stone.\\n- Harry confronted Snape and Quirrell, who was revealed to be working for Voldemort, and managed to thwart their plans and prevent them from obtaining the Sorcerer's Stone.\\n\\nThese actions and events played a crucial role in Harry's victory over Quirrell. If you need further analysis or information, feel free to let me know.\")}\n",
            "'--------------------'\n",
            "Replanning step\n",
            "state:\n",
            "{'input': 'how did harry beat quirrell?', 'anonymized_input': 'how did X beat Y?', 'plan': [\"Extract relevant chunks and chapter summaries related to Harry and Quirrell's final confrontation\", 'Analyze the extracted information to identify the key factors that contributed to Harry beating Quirrell', \"Determine the specific actions or events that led to Harry's victory\"], 'past_steps': 'Retrieve context for the book using run_retrieve_context function\\nThe context retrieved for \"Harry Potter and the Sorcerer\\'s Stone\" is from Chapter Thirteen. In this chapter, Harry is haunted by nightmares of his parents\\' death and the mysterious figure he saw in the Mirror of Erised. He, Ron, and Hermione continue their search for Nicolas Flamel, the maker of the Sorcerer\\'s Stone, and discover that Flamel is the only one who possesses the stone, which has the power to turn metal into gold and grant immortality.\\n\\nMeanwhile, tensions rise as Gryffindor prepares for a crucial Quidditch match against Hufflepuff, with Snape appointed as the referee, leading to concerns about biased officiating. Harry catches the Golden Snitch in record time during the match, securing Gryffindor\\'s victory and putting them in the lead for the house championship. Dumbledore congratulates Harry, and Snape appears visibly angry.\\n\\nLater, Harry witnesses Snape meeting with Quirrell in the Forbidden Forest, discussing the Sorcerer\\'s Stone and the obstacles guarding it. Harry shares this information with Ron and Hermione, realizing that Snape is trying to force Quirrell to help him obtain the Stone. They fear that the Stone is only safe as long as Quirrell resists Snape\\'s influence, raising concerns about the Stone\\'s safety.\\n\\nThis context provides insights into the events leading up to Harry\\'s victory and the challenges he faces in the pursuit of the Sorcerer\\'s Stone.\\nExtract relevant chunks and chapter summaries related to Harry and Quirrell\\'s final confrontation\\nI have retrieved the following information related to Harry beating Quirrell:\\n\\n### Key Factors that Contributed to Harry Beating Quirrell:\\n- Harry managed to get the Sorcerer\\'s Stone from the Mirror of Erised by lying to Quirrell and keeping him distracted.\\n- Quirrell\\'s true form was revealed to be Voldemort\\'s face on the back of his head, and he was unable to touch Harry due to the protection of his mother\\'s love.\\n- Dumbledore arrived in time to save Harry and stop Quirrell, contributing to Harry\\'s victory.\\n\\n### Specific Actions or Events that Led to Harry\\'s Victory:\\n- Harry successfully completed his final exams at Hogwarts despite the looming threat of Voldemort.\\n- Harry, Ron, and Hermione suspected Snape of planning to steal the Sorcerer\\'s Stone and took action to stop him.\\n- They navigated through various obstacles, including a giant chessboard and a series of enchantments guarding the Stone.\\n- Harry confronted Snape and Quirrell, who was revealed to be working for Voldemort, and managed to thwart their plans and prevent them from obtaining the Sorcerer\\'s Stone.\\n\\nThese actions and events played a crucial role in Harry\\'s victory over Quirrell. If you need further analysis or information, feel free to let me know.', 'mapping': {'X': 'Harry', 'Y': 'Quirrell'}}\n",
            "Checking if should end\n",
            " curr step: {'response': {'response': \"Harry beat Quirrell by lying to him and keeping him distracted, and also due to the protection of his mother's love, which prevented Quirrell from touching him.\"}}\n",
            "'--------------------'\n",
            "The final answer is: {'response': \"Harry beat Quirrell by lying to him and keeping him distracted, and also due to the protection of his mother's love, which prevented Quirrell from touching him.\"}\n"
          ]
        }
      ],
      "source": [
        "inputs = {\"input\": \"how did harry beat quirrell?\"}\n",
        "final_answer = execute_plan_and_print_steps(inputs)\n",
        "print(f'The final answer is: {final_answer}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Template for Answering Questions Using Context-Specific Information\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBKQkR-W4ZyV"
      },
      "source": [
        "### Model Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ME52zvjPNv47"
      },
      "outputs": [],
      "source": [
        "questions = [\n",
        "    \"Who gave Harry Potter his first broomstick?\",\n",
        "    \"What is the name of the three-headed dog guarding the Sorcerer's Stone?\",\n",
        "    \"Which house did the Sorting Hat initially consider for Harry?\",\n",
        "    \"What is the name of Harry's owl?\"\n",
        "]\n",
        "#     \"How did Harry and his friends get past Fluffy?\",\n",
        "#     \"What is the Mirror of Erised?\",\n",
        "#     \"Who tried to steal the Sorcerer's Stone?\",\n",
        "#     \"How did Harry defeat Quirrell/Voldemort?\",\n",
        "#     \"What is Harry's parent's secret weapon against Voldemort?\",\n",
        "# ]\n",
        "\n",
        "ground_truth_answers = [\n",
        "    \"Professor McGonagall\",\n",
        "    \"Fluffy\",\n",
        "    \"Slytherin\",\n",
        "    \"Hedwig\",\n",
        "    # \"They played music to put Fluffy to sleep.\",\n",
        "    # \"A magical mirror that shows the 'deepest, most desperate desire of our hearts.'\",\n",
        "    # \"Professor Quirrell, possessed by Voldemort\",\n",
        "    # \"Harry's mother's love protected him, causing Quirrell/Voldemort pain when they touched him.\",\n",
        "    # \"Love\",\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generating Answers and Retrieving Documents for Predefined Questions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "Wo9EEV0j4mJA",
        "outputId": "14c46214-8fb8-41aa-9845-73367d9a738f"
      },
      "outputs": [],
      "source": [
        "generated_answers = []\n",
        "retrieved_documents = []\n",
        "for question in questions:\n",
        "    result, all_context_book, all_context_summaries = answer_question_pipeline(question, chunks_retriever, chapter_summaries_retriever, answer_from_context_llm_chain, multi_query_retriver_llm)\n",
        "    generated_answers.append(result['text'])\n",
        "    retrieved_documents.append(all_context_book + all_context_summaries)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Displaying Retrieved Documents and Generated Answers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f'retrieved_documents: {retrieved_documents}\\n')\n",
        "print(f'generated_answers: {generated_answers}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preparing Data and Conducting Ragas Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for Ragas evaluation\n",
        "data_samples = {\n",
        "    'question': questions,  # Replace with your list of questions\n",
        "    'answer': generated_answers,  # Replace with your list of generated answers\n",
        "    'contexts': retrieved_documents,  # Your retrieved_documents list\n",
        "    'ground_truth': ground_truth_answers  # Replace with your list of ground truth answers\n",
        "}\n",
        "\n",
        "# Convert contexts to list of strings (if necessary)\n",
        "data_samples['contexts'] = [list(context) for context in data_samples['contexts']]\n",
        "\n",
        "dataset = Dataset.from_dict(data_samples)\n",
        "\n",
        "# Evaluate using Ragas with the specified metrics\n",
        "metrics = [\n",
        "    answer_correctness,\n",
        "    faithfulness,\n",
        "    answer_relevancy,\n",
        "    context_recall,\n",
        "    answer_similarity\n",
        "]\n",
        "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4-1106-preview\", max_tokens=4000)\n",
        "score = evaluate(dataset, metrics=metrics, llm=llm)\n",
        "\n",
        "# Print results and explanations\n",
        "results_df = score.to_pandas()\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Analyzing Metric Results from Ragas Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "analyse_metric_results(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Interactive Chat Interface for Harry Potter Inquiries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lV7UvEofS1nv"
      },
      "outputs": [],
      "source": [
        "def chat_with_data(chunks_retriever, chapter_summaries_retriever, answer_from_context_llm_chain, multi_query_retriver_llm):\n",
        "    \"\"\"\n",
        "    Provides an interactive chat interface for answering questions about Harry Potter.\n",
        "\n",
        "    Args:\n",
        "        retriever: A retriever for retrieving relevant documents.\n",
        "        chapter_summaries_retriever: A retriever for retrieving relevant chapter summaries.\n",
        "        answer_from_context_llm_chain: An LLM chain for answering questions based on context.\n",
        "        multi_query_retriver_llm: An LLM for use in the MultiQueryRetriever.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"You can start chatting with me about Harry Potter. Type 'exit' to stop.\")\n",
        "\n",
        "    while True:\n",
        "        # Prompt the user for a question\n",
        "        question = input(\"What's your question? \\n\")\n",
        "\n",
        "        # Check if the user wants to exit\n",
        "        if question.lower() == 'exit':\n",
        "            print(\"Exiting chat. Goodbye!\")\n",
        "            break\n",
        "\n",
        "        # Answer the question using the pipeline\n",
        "        result, _, _ = answer_question_pipeline(\n",
        "            question, chunks_retriever, chapter_summaries_retriever, answer_from_context_llm_chain, multi_query_retriver_llm\n",
        "        )\n",
        "\n",
        "        # Print the answer\n",
        "        print(\"Answer:\")\n",
        "        wrapped_result = textwrap.fill(result['text'], width=120)  # Wrap text for readability\n",
        "        print(wrapped_result)\n",
        "        print(\"-\" * 80)  # Print a separator line for readability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Calling the chat_with_data function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "048b2Ol7QAiF",
        "outputId": "1c891083-5c91-4425-ba23-50d1f32e0ac5"
      },
      "outputs": [],
      "source": [
        "chat_with_data(chunks_retriever,chapter_summaries_retriever, answer_from_context_llm_chain, multi_query_retriver_llm)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
