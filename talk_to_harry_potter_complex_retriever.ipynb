{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjDmS3Cn2jKm",
        "outputId": "569cfc27-0dbb-455a-85cb-3a75b57bbbf2"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install tiktoken\n",
        "!pip install faiss-gpu\n",
        "!pip install langchain_experimental\n",
        "!pip install \"langchain[docarray]\"\n",
        "!pip install pylcs\n",
        "!pip3 install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XIL5OCqJ7bh8"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.document_loaders import  PyPDFLoader\n",
        "from langchain.vectorstores import  FAISS\n",
        "from langchain.text_splitter import  RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings  # Remove HuggingFaceInstructEmbeddings if not used\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from time import monotonic\n",
        "\n",
        "\n",
        "import pylcs\n",
        "import textwrap\n",
        "import os\n",
        "import re\n",
        "import copy\n",
        "import tiktoken\n",
        "import ast\n",
        "import PyPDF2\n",
        "from datasets import Dataset\n",
        "from ragas import evaluate\n",
        "from ragas.metrics import (\n",
        "    answer_correctness,\n",
        "    faithfulness,\n",
        "    answer_relevancy,\n",
        "    context_recall,\n",
        "    answer_similarity\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6QeKRm37HwC"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJ_QFM5S2nyK",
        "outputId": "93549ee6-0afb-41db-d67c-4355f946570c"
      },
      "outputs": [],
      "source": [
        "# Prompt the user for their OpenAI API key\n",
        "api_key = input(\"Please enter your OpenAI API key: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WsKZUN02pAI",
        "outputId": "11e3ae7a-e2ed-4224-c1e6-17f4316dd6f4"
      },
      "outputs": [],
      "source": [
        "# Set the API key as an environment variable\n",
        "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "# Optionally, check that the environment variable was set correctly\n",
        "print(\"OPENAI_API_KEY has been set!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8mUYHG_S6y22"
      },
      "outputs": [],
      "source": [
        "hp_pdf_path =\"Harry_Potter_Book_1_The_Sorcerers_Stone.pdf\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmtLiio3TGaf"
      },
      "outputs": [],
      "source": [
        "def split_into_chapters(book_path):\n",
        "    with open(book_path, 'rb') as pdf_file:\n",
        "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "        documents = pdf_reader.pages\n",
        "        text = \" \".join([doc.extract_text() for doc in documents])\n",
        "\n",
        "        # Adjust the pattern as needed based on the chapter titles' formatting\n",
        "        chapters = re.split(r'(CHAPTER\\s[A-Z]+(?:\\s[A-Z]+)*)', text)\n",
        "\n",
        "        # Create Document objects with only chapter metadata\n",
        "        chapter_docs = []\n",
        "        chapter_num = 1\n",
        "        for i in range(1, len(chapters), 2):\n",
        "            chapter_text = chapters[i] + chapters[i + 1]\n",
        "            doc = Document(page_content=chapter_text, metadata={\"chapter\": chapter_num})\n",
        "            chapter_docs.append(doc)\n",
        "            chapter_num += 1\n",
        "\n",
        "    return chapter_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDHfDODdTIBY"
      },
      "outputs": [],
      "source": [
        "chapters = split_into_chapters(hp_pdf_path) # with additional metadata of chapter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ct-zRX5X1PU",
        "outputId": "d99c0936-a0de-461d-b3fb-c5b95d32abfb"
      },
      "outputs": [],
      "source": [
        "print(len(chapters))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XG4FgB6JYUc"
      },
      "outputs": [],
      "source": [
        "def replace_t_with_space(list_of_documents):\n",
        "    for doc in list_of_documents:\n",
        "        doc.page_content = doc.page_content.replace('\\t', ' ')\n",
        "    return list_of_documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FH0HH26WJOb"
      },
      "outputs": [],
      "source": [
        "chapters = replace_t_with_space(chapters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49RqsAhDxjFg"
      },
      "outputs": [],
      "source": [
        "summarization_prompt_template = \"\"\"Write an extensive summary of about of the following:\n",
        "\n",
        "{text}\n",
        "\n",
        "SUMMARY:\"\"\"\n",
        "\n",
        "summarization_prompt = PromptTemplate(template=summarization_prompt_template, input_variables=[\"text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47Trz9fSxuaF"
      },
      "outputs": [],
      "source": [
        "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
        "    encoding = tiktoken.encoding_for_model(encoding_name)\n",
        "    num_tokens = len(encoding.encode(string))\n",
        "    return num_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkQm0tqX9kAL"
      },
      "outputs": [],
      "source": [
        "def replace_double_lines_with_one_line(text):\n",
        "  cleaned_text = re.sub(r'\\n\\n', '\\n', text)\n",
        "  return cleaned_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehe6iObnx4l9"
      },
      "outputs": [],
      "source": [
        "def create_chapter_summary(chapter):\n",
        "  chapter_txt = chapter.page_content\n",
        "  model_name = \"gpt-3.5-turbo-0125\"\n",
        "  llm = ChatOpenAI(temperature=0, model_name=model_name)\n",
        "\n",
        "  gpt_35_turbo_max_tokens = 16000\n",
        "  verbose = False\n",
        "\n",
        "  num_tokens = num_tokens_from_string(chapter_txt, model_name)\n",
        "\n",
        "  if num_tokens < gpt_35_turbo_max_tokens:\n",
        "    chain = load_summarize_chain(llm, chain_type=\"stuff\", prompt=summarization_prompt, verbose=verbose)\n",
        "  else:\n",
        "    chain = load_summarize_chain(llm, chain_type=\"map_reduce\", map_prompt=summarization_prompt, combine_prompt=summarization_prompt, verbose=verbose)\n",
        "\n",
        "  start_time = monotonic()\n",
        "  doc_chapter = Document(page_content=chapter_txt)\n",
        "  summary = chain.invoke([doc_chapter])\n",
        "\n",
        "\n",
        "  print(f\"Chain type: {chain.__class__.__name__}\")\n",
        "  print(f\"Run time: {monotonic() - start_time}\")\n",
        "  summary = replace_double_lines_with_one_line(summary[\"output_text\"])\n",
        "  doc_summary = Document(page_content=summary, metadata=chapter.metadata)\n",
        "  return doc_summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4UBurLsMCHj",
        "outputId": "668932cf-02d8-446d-e0ed-3f85b30d3bba"
      },
      "outputs": [],
      "source": [
        "chapter_summaries = []\n",
        "for chapter in chapters:\n",
        "    chapter_summaries.append(create_chapter_summary(chapter))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9t1Kq6fGS0EA"
      },
      "outputs": [],
      "source": [
        "def encode_book(path,chunk_size=1000,chunk_overlap=200):\n",
        "    loader = PyPDFLoader(path)\n",
        "    documents = loader.load()\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap, length_function=len)\n",
        "    texts = text_splitter.split_documents(documents)\n",
        "    cleaned_texts = copy.deepcopy(texts)\n",
        "    for text in cleaned_texts:\n",
        "        text.page_content = text.page_content.replace('\\t', ' ')  # Replace tab characters with spaces\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "    vectorstore = FAISS.from_documents(cleaned_texts, embeddings)\n",
        "    return vectorstore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHt9Y12gMp2z"
      },
      "outputs": [],
      "source": [
        "def encode_chapter_summaries(chapter_summaries):\n",
        "  embeddings = OpenAIEmbeddings()\n",
        "  chapter_summaries_vectorstore = FAISS.from_documents(chapter_summaries, embeddings)\n",
        "  return chapter_summaries_vectorstore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TpVkNzd1hs8v"
      },
      "outputs": [],
      "source": [
        "modifier_prompt_template = \"\"\"\n",
        "You are an expert on analyzing and understanding books based solely on their textual content. You have no prior knowledge about the specific book in the question.\n",
        "If you ever read the related book before, FORGET ANYTHING about it.\n",
        "You have access to two vector stores:\n",
        "\n",
        "• One containing all the book content divided into chunks of 1000 characters with 200 character overlap.\n",
        "• Another containing summaries of each chapter, approximately 250 tokens each.\n",
        "\n",
        "Given a user's question about the book, your task is to generate a list of no more than 3 sub-questions that can be used as queries to retrieve relevant information from the vector stores based on semantic similarity. These sub-questions should be designed to collectively cover all the information needed to answer the original question comprehensively, without relying on any prior knowledge of the book's plot, characters, or events.\n",
        "\n",
        "When generating the sub-questions, consider the following:\n",
        "\n",
        "\n",
        "1.No Pre-knowledge: you're unaware of the book's details like plot or characters. The sub-questions must not present any prior knowledge of the book.\n",
        "2.Directly Derived: Create sub-questions strictly from the user's question, aiming to retrieve book information without presupposing specific plot details or events.\n",
        "3.Break Down: Decompose the user's question into finer, detailed sub-questions using only the textual content provided.\n",
        "4.Key Concepts: Identify essential information needed from the original question and form targeted sub-questions to gather this data.\n",
        "5.Self-contained Queries: Each sub-question should stand alone for effective vector store querying through semantic similarity.\n",
        "6.Logical Sequence: Arrange sub-questions in a logical order that collectively provides a thorough answer.\n",
        "7.Efficiency: Ensure sub-questions are unique and focused to avoid redundant searches and streamline information retrieval.\n",
        "\n",
        "Output your response as a Python list, where each item is a self-contained sub-question that can be used as a standalone query for vector retrieval.\n",
        "\n",
        "User's question: {question}\n",
        "\"\"\"\n",
        "modifier_prompt = PromptTemplate(\n",
        "input_variables=[\"question\"],\n",
        "template=modifier_prompt_template,\n",
        ")\n",
        "\n",
        "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4-1106-preview\", max_tokens=4000)\n",
        "\n",
        "question_modifier_llm_chain = LLMChain(llm=llm, prompt=modifier_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwSLdGdb1FiO"
      },
      "outputs": [],
      "source": [
        "def modify_question(question):\n",
        "    result = question_modifier_llm_chain.invoke(input=question)\n",
        "    modified_questions_str = result['text']\n",
        "    print(\"Original Output:\", modified_questions_str)\n",
        "\n",
        "    # Remove the Markdown code block syntax and the variable assignment part\n",
        "    clean_str = modified_questions_str.replace(\"```python\", \"\").replace(\"```\", \"\").strip()\n",
        "    clean_str = clean_str.replace(\"sub_questions = \", \"\").strip()\n",
        "\n",
        "    # Dedent the string to remove unexpected indents\n",
        "    clean_str = textwrap.dedent(clean_str)\n",
        "\n",
        "    try:\n",
        "        modified_questions = ast.literal_eval(clean_str)\n",
        "    except SyntaxError as e:\n",
        "        print(f\"Syntax error during ast.literal_eval: {e}\")\n",
        "        modified_questions = []  # Default to an empty list in case of error\n",
        "\n",
        "    return modified_questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXfrK0m5DUq8"
      },
      "outputs": [],
      "source": [
        "question = \"how did harry beat quirrell?\"\n",
        "modified_question = modify_question(question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEFLePy-0YS3"
      },
      "outputs": [],
      "source": [
        "def create_context_per_question(question, multi_query_retriever, multi_query_retriever_chapter_summaries):\n",
        "    # Retrieve relevant documents based on the question\n",
        "    docs = multi_query_retriever.get_relevant_documents(question)\n",
        "    docs_summaries = multi_query_retriever_chapter_summaries.get_relevant_documents(question)\n",
        "\n",
        "    # Concatenate the relevant content with citation information\n",
        "    context = \" \".join(doc.page_content for doc in docs)\n",
        "\n",
        "    # context = \" \".join(f\"{doc.page_content} (Chapter {doc.metadata['chapter']}, Page {doc.metadata['page']})\" for doc in docs)\n",
        "    context_summaries = \"\".join(f\"{doc.page_content} (Chapter {doc.metadata['chapter']})\" for doc in docs_summaries)\n",
        "\n",
        "    return context, context_summaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXFPHxmSC6W4"
      },
      "outputs": [],
      "source": [
        "def is_similarity_ratio_lower_than_th(large_string, short_string, th):\n",
        "  lcs = pylcs.lcs_sequence_length(large_string,short_string)\n",
        "  if lcs / len(short_string) < th:\n",
        "    return True\n",
        "  return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjk7u5ME7ZzX"
      },
      "outputs": [],
      "source": [
        "def answer_question_pipline(question,retriever,chapter_summaries_retriever, answer_from_context_llm_chain, multi_query_retriver_llm):\n",
        "        multi_query_retriever = MultiQueryRetriever.from_llm(retriever=retriever, llm=multi_query_retriver_llm)\n",
        "        multi_query_retriever_chapter_summaries = MultiQueryRetriever.from_llm(retriever=chapter_summaries_retriever, llm=multi_query_retriver_llm)\n",
        "\n",
        "        modified_questions = modify_question(question)\n",
        "        all_context_book = \"\"\n",
        "        all_context_summaries = \"\"\n",
        "        similarity_th = 0.5\n",
        "\n",
        "\n",
        "        for modified_question in modified_questions:\n",
        "            curr_question_relevant_context, curr_question_relevant_summaries_context = create_context_per_question(modified_question, multi_query_retriever, multi_query_retriever_chapter_summaries)\n",
        "\n",
        "            if is_similarity_ratio_lower_than_th(all_context_book, curr_question_relevant_context, similarity_th):\n",
        "                all_context_book += curr_question_relevant_context\n",
        "            if is_similarity_ratio_lower_than_th(all_context_summaries, curr_question_relevant_summaries_context, similarity_th):\n",
        "                all_context_summaries += curr_question_relevant_summaries_context\n",
        "\n",
        "        all_context = all_context_book + all_context_summaries\n",
        "\n",
        "        input_data = {\n",
        "        \"context\": all_context,  # Your context string\n",
        "        \"question\": question  # Your question string\n",
        "        }\n",
        "\n",
        "        # Execute the chain and get the response\n",
        "        result = answer_from_context_llm_chain.invoke(input=input_data)\n",
        "        return result, all_context_book, all_context_summaries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lV7UvEofS1nv"
      },
      "outputs": [],
      "source": [
        "def chat_with_data(retriever,chapter_summaries_retriever, answer_from_context_llm_chain, multi_query_retriver_llm):\n",
        "    print(\"You can start chatting with me about Harry Potter. Type 'exit' to stop.\")\n",
        "    while True:\n",
        "        # Prompt the user for a question\n",
        "        question = input(\"What's your question? \\n\")\n",
        "\n",
        "        # Check if the user wants to exit\n",
        "        if question.lower() == 'exit':\n",
        "            print(\"Exiting chat. Goodbye!\")\n",
        "            break\n",
        "\n",
        "        # Execute the chain and get the response\n",
        "        result, _, _ = answer_question_pipline(question,retriever,chapter_summaries_retriever, answer_from_context_llm_chain, multi_query_retriver_llm)\n",
        "\n",
        "        # Print the response\n",
        "\n",
        "        print(\"Answer:\")\n",
        "        wrapped_result = textwrap.fill(result['text'], width=120)\n",
        "        print(wrapped_result)\n",
        "        print(\"-\" * 80)  # Print a separator line for readability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bWP7iLNS6Ey"
      },
      "outputs": [],
      "source": [
        "vector_store = encode_book(hp_pdf_path,chunk_size=1000,chunk_overlap=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmk3ZDtiPxzQ"
      },
      "outputs": [],
      "source": [
        "chapter_summaries_vector_store = encode_chapter_summaries(chapter_summaries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtEVVzHCP4uz"
      },
      "outputs": [],
      "source": [
        "retriever=vector_store.as_retriever(search_kwargs={\"k\": 4})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_iD1Zz1uP8Zn"
      },
      "outputs": [],
      "source": [
        "chapter_summaries_retriever = chapter_summaries_vector_store.as_retriever(search_kwargs={\"k\": 4})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SV6v5-ajP_i-"
      },
      "outputs": [],
      "source": [
        "agent_answer_prompt_template = \"\"\"\n",
        "Based solely on the information provided in this context, and without using any information outside of this context, please answer the following question as concisely and as shortly as possible. You can rephrase the question for better fitting to the context.\n",
        "\n",
        "Context:{context}\n",
        "Question:{question}\n",
        "\n",
        "**If the answer cannot be derived from the context, or if it requires knowledge from outside sources, simply answer: \"I don't know\".**\n",
        "\n",
        "Please cite specific parts of the context in your answer to demonstrate how it supports your response.\n",
        "If the chapter number of the relevant context appears, specify it in your answer.\n",
        "\"\"\"\n",
        "agent_answer_prompt = PromptTemplate(\n",
        "input_variables=[\"context\", \"question\"],\n",
        "template=agent_answer_prompt_template,\n",
        ")\n",
        "\n",
        "multi_query_retriver_llm = ChatOpenAI(temperature=0, model_name=\"gpt-4-1106-preview\", max_tokens=4000)\n",
        "\n",
        "answer_from_context_llm_chain = LLMChain(llm=llm, prompt=agent_answer_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YlJOyrULV5c"
      },
      "outputs": [],
      "source": [
        "question = 'how did harry beat quirrell?'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fgs-qE6mLVBb"
      },
      "outputs": [],
      "source": [
        "result, all_context_book, all_context_summaries = answer_question_pipline(question,retriever,chapter_summaries_retriever, answer_from_context_llm_chain, multi_query_retriver_llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUEPhiHNUSP0"
      },
      "outputs": [],
      "source": [
        "wrapped_all_context_book = textwrap.fill(all_context_book, width=120)\n",
        "print(f' conetxt book: {wrapped_all_context_book} \\n')\n",
        "\n",
        "wrapped_all_context_summaries = textwrap.fill(all_context_summaries, width=120)\n",
        "print(f' context summaries: {wrapped_all_context_summaries} \\n')\n",
        "\n",
        "wrapped_result = textwrap.fill(result['text'], width=120)\n",
        "print(f' answer: {wrapped_result}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBKQkR-W4ZyV"
      },
      "source": [
        "## Model Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ME52zvjPNv47"
      },
      "outputs": [],
      "source": [
        "questions = [\n",
        "    \"Who gave Harry Potter his first broomstick?\",\n",
        "    \"What is the name of the three-headed dog guarding the Sorcerer's Stone?\",\n",
        "    \"Which house did the Sorting Hat initially consider for Harry?\",\n",
        "    \"What is the name of Harry's owl?\"\n",
        "]\n",
        "#     \"How did Harry and his friends get past Fluffy?\",\n",
        "#     \"What is the Mirror of Erised?\",\n",
        "#     \"Who tried to steal the Sorcerer's Stone?\",\n",
        "#     \"How did Harry defeat Quirrell/Voldemort?\",\n",
        "#     \"What is Harry's parent's secret weapon against Voldemort?\",\n",
        "# ]\n",
        "\n",
        "ground_truth_answers = [\n",
        "    \"Professor McGonagall\",\n",
        "    \"Fluffy\",\n",
        "    \"Slytherin\",\n",
        "    \"Hedwig\",\n",
        "    # \"They played music to put Fluffy to sleep.\",\n",
        "    # \"A magical mirror that shows the 'deepest, most desperate desire of our hearts.'\",\n",
        "    # \"Professor Quirrell, possessed by Voldemort\",\n",
        "    # \"Harry's mother's love protected him, causing Quirrell/Voldemort pain when they touched him.\",\n",
        "    # \"Love\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "Wo9EEV0j4mJA",
        "outputId": "14c46214-8fb8-41aa-9845-73367d9a738f"
      },
      "outputs": [],
      "source": [
        "generated_answers = []\n",
        "retrieved_documents = []\n",
        "for question in questions:\n",
        "    result, all_context_book, all_context_summaries = answer_question_pipline(question, retriever, chapter_summaries_retriever, answer_from_context_llm_chain, multi_query_retriver_llm)\n",
        "    generated_answers.append(result['text'])\n",
        "    retrieved_documents.append(all_context_book + all_context_summaries)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(retrieved_documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-LHwe3k-JXm",
        "outputId": "a82e5293-db47-497b-f0e3-c66370ec88d5"
      },
      "outputs": [],
      "source": [
        "generated_answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Prepare data for Ragas evaluation\n",
        "data_samples = {\n",
        "    'question': questions,  # Replace with your list of questions\n",
        "    'answer': generated_answers,  # Replace with your list of generated answers\n",
        "    'contexts': retrieved_documents,  # Your retrieved_documents list\n",
        "    'ground_truth': ground_truth_answers  # Replace with your list of ground truth answers\n",
        "}\n",
        "\n",
        "# Convert contexts to list of strings (if necessary)\n",
        "data_samples['contexts'] = [list(context) for context in data_samples['contexts']]\n",
        "\n",
        "dataset = Dataset.from_dict(data_samples)\n",
        "\n",
        "# Evaluate using Ragas with the specified metrics\n",
        "metrics = [\n",
        "    answer_correctness,\n",
        "    faithfulness,\n",
        "    answer_relevancy,\n",
        "    context_recall,\n",
        "    answer_similarity\n",
        "]\n",
        "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4-1106-preview\", max_tokens=4000)\n",
        "score = evaluate(dataset, metrics=metrics, llm=llm)\n",
        "\n",
        "# Print results and explanations\n",
        "results_df = score.to_pandas()\n",
        "print(results_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "def analyse_metric_results(results_df):\n",
        "    for metric_name, metric_value in results_df.items():\n",
        "        print(f\"\\n**{metric_name.upper()}**\")\n",
        "\n",
        "        # Extract the numerical value from the Series object\n",
        "        if isinstance(metric_value, pd.Series):\n",
        "            metric_value = metric_value.values[0]  # Assuming the value is at index 0\n",
        "\n",
        "        if metric_name == \"faithfulness\":\n",
        "            print(\"Measures how well the generated answer is supported by the retrieved documents.\")\n",
        "            print(f\"Score: {metric_value:.4f}\")\n",
        "            # Interpretation: Higher score indicates better faithfulness.\n",
        "        elif metric_name == \"answer_relevancy\":\n",
        "            print(\"Measures how relevant the generated answer is to the question.\")\n",
        "            print(f\"Score: {metric_value:.4f}\")\n",
        "            # Interpretation: Higher score indicates better relevance.\n",
        "        elif metric_name == \"context_precision\":\n",
        "            print(\"Measures the proportion of retrieved documents that are actually relevant.\")\n",
        "            print(f\"Score: {metric_value:.4f}\")\n",
        "            # Interpretation: Higher score indicates better precision (avoiding irrelevant documents).\n",
        "        elif metric_name == \"context_relevancy\":\n",
        "            print(\"Measures how relevant the retrieved documents are to the question.\")\n",
        "            print(f\"Score: {metric_value:.4f}\")\n",
        "            # Interpretation: Higher score indicates better relevance of retrieved documents.\n",
        "        elif metric_name == \"context_recall\":\n",
        "            print(\"Measures the proportion of relevant documents that are successfully retrieved.\")\n",
        "            print(f\"Score: {metric_value:.4f}\")\n",
        "            # Interpretation: Higher score indicates better recall (finding all relevant documents).\n",
        "        elif metric_name == \"context_entity_recall\":\n",
        "            print(\"Measures the proportion of relevant entities mentioned in the question that are also found in the retrieved documents.\")\n",
        "            print(f\"Score: {metric_value:.4f}\")\n",
        "            # Interpretation: Higher score indicates better recall of relevant entities.\n",
        "        elif metric_name == \"answer_similarity\":\n",
        "            print(\"Measures the semantic similarity between the generated answer and the ground truth answer.\")\n",
        "            print(f\"Score: {metric_value:.4f}\")\n",
        "            # Interpretation: Higher score indicates closer semantic meaning between the answers.\n",
        "        elif metric_name == \"answer_correctness\":\n",
        "            print(\"Measures whether the generated answer is factually correct.\")\n",
        "            print(f\"Score: {metric_value:.4f}\")\n",
        "            # Interpretation: Higher score indicates better correctness."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "analyse_metric_results(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "048b2Ol7QAiF",
        "outputId": "1c891083-5c91-4425-ba23-50d1f32e0ac5"
      },
      "outputs": [],
      "source": [
        "chat_with_data(retriever,chapter_summaries_retriever, answer_from_context_llm_chain, multi_query_retriver_llm)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
