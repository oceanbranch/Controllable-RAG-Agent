{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langgraph.graph import END\n",
    "from IPython.display import display, Image\n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "## dummy functions for comprehensive visualization\n",
    "\n",
    "class PlanExecute:\n",
    "    pass\n",
    "def anonymize_queries():\n",
    "    pass\n",
    "def plan_step():\n",
    "    pass\n",
    "def break_down_plan_step():\n",
    "    pass\n",
    "\n",
    "def deanonymize_queries():\n",
    "    pass\n",
    "def run_qualitative_chunks_retrieval_workflow ():\n",
    "    pass\n",
    "\n",
    "def run_qualitative_summaries_retrieval_workflow ():\n",
    "    pass\n",
    "\n",
    "def run_qualitative_quotes_retrieval_workflow ():\n",
    "    pass\n",
    "def run_qualtative_answer_workflow ():\n",
    "    pass\n",
    "def run_task_handler_chain ():\n",
    "    pass\n",
    "def replan_step ():\n",
    "    pass\n",
    "def run_qualtative_answer_workflow_for_final_answer ():\n",
    "    pass\n",
    "def retrieve_or_answer ():\n",
    "    pass\n",
    "def can_be_answered ():\n",
    "    pass\n",
    "\n",
    "def keep_only_relevant_content ():\n",
    "    pass\n",
    "\n",
    "def is_distilled_content_grounded_on_content ():\n",
    "    pass\n",
    "\n",
    "def is_answer_grounded_on_context ():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "At 'task_handler' node, 'retrieve_or_answer' branch found unknown target 'retrieve_chunks'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 90\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# After getting the final answer we check if the answer is grounded on context, if yes we go to END, if not we go to get_final_answer\u001b[39;00m\n\u001b[0;32m     84\u001b[0m agent_workflow\u001b[38;5;241m.\u001b[39madd_conditional_edges(\n\u001b[0;32m     85\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_final_answer\u001b[39m\u001b[38;5;124m\"\u001b[39m,is_answer_grounded_on_context ,{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhallucination\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_final_answer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrounded on context\u001b[39m\u001b[38;5;124m\"\u001b[39m:END}\n\u001b[0;32m     86\u001b[0m \n\u001b[0;32m     87\u001b[0m )\n\u001b[1;32m---> 90\u001b[0m plan_and_execute_app \u001b[38;5;241m=\u001b[39m \u001b[43magent_workflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m display(Image(plan_and_execute_app\u001b[38;5;241m.\u001b[39mget_graph(xray\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mdraw_mermaid_png()))\n",
      "File \u001b[1;32mc:\\Users\\N7\\PycharmProjects\\llm_tasks\\RAG-Harry-Potter\\.venv\\Lib\\site-packages\\langgraph\\graph\\state.py:177\u001b[0m, in \u001b[0;36mStateGraph.compile\u001b[1;34m(self, checkpointer, interrupt_before, interrupt_after, debug)\u001b[0m\n\u001b[0;32m    174\u001b[0m interrupt_after \u001b[38;5;241m=\u001b[39m interrupt_after \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[0;32m    176\u001b[0m \u001b[38;5;66;03m# validate the graph\u001b[39;00m\n\u001b[1;32m--> 177\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m*\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minterrupt_after\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m*\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;66;03m# prepare output channels\u001b[39;00m\n\u001b[0;32m    186\u001b[0m state_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchannels)\n",
      "File \u001b[1;32mc:\\Users\\N7\\PycharmProjects\\llm_tasks\\RAG-Harry-Potter\\.venv\\Lib\\site-packages\\langgraph\\graph\\graph.py:273\u001b[0m, in \u001b[0;36mGraph.validate\u001b[1;34m(self, interrupt)\u001b[0m\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m end \u001b[38;5;129;01min\u001b[39;00m branch\u001b[38;5;241m.\u001b[39mends\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m    272\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes \u001b[38;5;129;01mand\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m END:\n\u001b[1;32m--> 273\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    274\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m node, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcond\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m branch found unknown target \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    275\u001b[0m             )\n\u001b[0;32m    276\u001b[0m         all_targets\u001b[38;5;241m.\u001b[39madd(end)\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: At 'task_handler' node, 'retrieve_or_answer' branch found unknown target 'retrieve_chunks'"
     ]
    }
   ],
   "source": [
    "agent_workflow = StateGraph(PlanExecute)\n",
    "\n",
    "# Add the anonymize node\n",
    "agent_workflow.add_node(\"anonymize_question\", anonymize_queries)\n",
    "\n",
    "# Add the plan node\n",
    "agent_workflow.add_node(\"planner\", plan_step)\n",
    "\n",
    "# Add the break down plan node\n",
    "\n",
    "agent_workflow.add_node(\"break_down_plan_to_retrieve_or_answer\", break_down_plan_step)\n",
    "\n",
    "# Add the deanonymize node\n",
    "agent_workflow.add_node(\"de_anonymize_plan\", deanonymize_queries)\n",
    "\n",
    "# Add the qualitative retrieval node\n",
    "agent_workflow.add_node(\"retrieve_book_chunks\", run_qualitative_chunks_retrieval_workflow)\n",
    "\n",
    "agent_workflow.add_node(\"retrieve_book_summaries\", run_qualitative_summaries_retrieval_workflow)\n",
    "\n",
    "agent_workflow.add_node(\"retrieve_book_quotes\", run_qualitative_quotes_retrieval_workflow)\n",
    "\n",
    "# Add the qualitative answer node\n",
    "agent_workflow.add_node(\"answer\", run_qualtative_answer_workflow)\n",
    "\n",
    "# Add the task handler node\n",
    "agent_workflow.add_node(\"task_handler\", run_task_handler_chain)\n",
    "\n",
    "# Add a replan node\n",
    "agent_workflow.add_node(\"replan\", replan_step)\n",
    "\n",
    "# Add answer from context node\n",
    "agent_workflow.add_node(\"get_final_answer\", run_qualtative_answer_workflow_for_final_answer)\n",
    "\n",
    "agent_workflow.add_node(\"keep_only_relevant_content\",keep_only_relevant_content)\n",
    "\n",
    "# Build the graph\n",
    "\n",
    "# Set the entry point\n",
    "agent_workflow.set_entry_point(\"anonymize_question\")\n",
    "\n",
    "# From anonymize we go to plan\n",
    "agent_workflow.add_edge(\"anonymize_question\", \"planner\")\n",
    "\n",
    "# From plan we go to deanonymize\n",
    "agent_workflow.add_edge(\"planner\", \"de_anonymize_plan\")\n",
    "\n",
    "# From deanonymize we go to break down plan to retrieve or answer\n",
    "agent_workflow.add_edge(\"de_anonymize_plan\", \"break_down_plan_to_retrieve_or_answer\")\n",
    "\n",
    "# From break_down_plan we go to task handler to decide whether to retrieve or answer\n",
    "agent_workflow.add_edge(\"break_down_plan_to_retrieve_or_answer\", \"task_handler\")\n",
    "\n",
    "# From task handler we go to either retrieve or answer\n",
    "agent_workflow.add_conditional_edges(\"task_handler\", retrieve_or_answer, {\"chosen_tool_is_retrieve_chunks\": \"retrieve_book_chunks\", \"chosen_tool_is_retrieve_summaries\":\n",
    "                                                                            \"retrieve_summaries\", \"chosen_tool_is_retrieve_quotes\": \"retrieve_book_quotes\", \"chosen_tool_is_answer\": \"answer\"})\n",
    "\n",
    "# From retrieve we go to keep_only_relevant_content to distill content\n",
    "agent_workflow.add_edge(\"retrieve_book_chunks\", \"keep_only_relevant_content\")\n",
    "\n",
    "agent_workflow.add_edge(\"retrieve_book_summaries\", \"keep_only_relevant_content\")\n",
    "\n",
    "agent_workflow.add_edge(\"retrieve_book_quotes\", \"keep_only_relevant_content\")\n",
    "\n",
    "# distill content and check if it is grounded on context, if not grounded we distill the content again\n",
    "agent_workflow.add_conditional_edges(\n",
    "    \"keep_only_relevant_content\",\n",
    "    is_distilled_content_grounded_on_content,\n",
    "    {\"grounded on the original context\":\"replan\",\n",
    "      \"not grounded on the original context\":\"keep_only_relevant_content\"},\n",
    "    )\n",
    "\n",
    "# After answering we go to replan if the answer is grounded on context, if not we answer again\n",
    "agent_workflow.add_conditional_edges(\n",
    "\"answer\",is_answer_grounded_on_context ,{\"hallucination\":\"answer\", \"grounded on context\":\"replan\"}\n",
    "\n",
    ")\n",
    "\n",
    "# After replanning we check if the question can be answered, if yes we go to get_final_answer, if not we go to task_handler\n",
    "agent_workflow.add_conditional_edges(\"replan\",can_be_answered, {\"can_be_answered_already\": \"get_final_answer\", \"cannot_be_answered_yet\": \"break_down_plan_to_retrieve_or_answer\"})\n",
    "\n",
    "\n",
    "# After getting the final answer we check if the answer is grounded on context, if yes we go to END, if not we go to get_final_answer\n",
    "agent_workflow.add_conditional_edges(\n",
    "\"get_final_answer\",is_answer_grounded_on_context ,{\"hallucination\":\"get_final_answer\", \"grounded on context\":END}\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "plan_and_execute_app = agent_workflow.compile()\n",
    "\n",
    "display(Image(plan_and_execute_app.get_graph(xray=True).draw_mermaid_png()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
